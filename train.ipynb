{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in /home/mp6021/.local/lib/python3.8/site-packages (1.11.0+cu113)\n",
      "Requirement already satisfied: torchvision in /home/mp6021/.local/lib/python3.8/site-packages (0.12.0+cu113)\n",
      "Requirement already satisfied: torchaudio in /home/mp6021/.local/lib/python3.8/site-packages (0.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /home/mp6021/.local/lib/python3.8/site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: requests in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchvision) (2.24.0)\n",
      "Requirement already satisfied: numpy in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (2020.6.20)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorboardX in /home/mp6021/.local/lib/python3.8/site-packages (2.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/mp6021/.local/lib/python3.8/site-packages (from tensorboardX) (3.19.4)\n",
      "Requirement already satisfied: six in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from tensorboardX) (1.15.0)\n",
      "Requirement already satisfied: numpy in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from tensorboardX) (1.19.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-image in /home/mp6021/.local/lib/python3.8/site-packages (0.19.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from scikit-image) (20.4)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from scikit-image) (8.0.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/mp6021/.local/lib/python3.8/site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/mp6021/.local/lib/python3.8/site-packages (from scikit-image) (2.16.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/mp6021/.local/lib/python3.8/site-packages (from scikit-image) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from scikit-image) (1.19.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/mp6021/.local/lib/python3.8/site-packages (from scikit-image) (2022.3.25)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/scipy-1.5.2-py3.8-linux-x86_64.egg (from scikit-image) (1.5.2)\n",
      "Requirement already satisfied: six in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from packaging>=20.0->scikit-image) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from packaging>=20.0->scikit-image) (2.4.7)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from Models.EncoderModel import EncoderModel\n",
    "from Models.DecoderModel import DecoderModel\n",
    "from Models.PoseCNN import PoseCNN\n",
    "from Models.BackprojectDepth import BackprojectDepth\n",
    "from Models.Project3D import Project3D\n",
    "from Dataset.KITTI import KITTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, LR=0.001, batchSize=12, epochs=20, height=192, width=640, frameIdxs=[0, -1, 1],\n",
    "                 scales=[0, 1, 2, 3]):\n",
    "        self.LR = LR\n",
    "        self.batchSize = batchSize\n",
    "        self.epochs = epochs\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.frameIdxs = frameIdxs\n",
    "        self.numScales = len(scales)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(self.device)\n",
    "        self.models = {}\n",
    "        self.trainableParameters = []\n",
    "        self.models[\"encoder\"] = EncoderModel(50)\n",
    "        self.models[\"encoder\"] = self.models[\"encoder\"].to(self.device)\n",
    "        self.trainableParameters += list(self.models[\"encoder\"].parameters())\n",
    "        self.models[\"decoder\"] = DecoderModel(self.models[\"encoder\"].numChannels)\n",
    "        self.models[\"decoder\"] = self.models[\"decoder\"].to(self.device)\n",
    "        self.trainableParameters += list(self.models[\"decoder\"].parameters())\n",
    "        self.models[\"pose\"] = PoseCNN(len(self.frameIdxs))\n",
    "        self.models[\"pose\"] = self.models[\"pose\"].to(self.device)\n",
    "        self.trainableParameters += list(self.models[\"pose\"].parameters())\n",
    "        self.optimizer = optim.Adam(self.trainableParameters, lr=self.LR)\n",
    "        self.lrScheduler = optim.lr_scheduler.StepLR(self.optimizer, 15, 0.1)\n",
    "        self.loadDataset()\n",
    "        self.depthMetricNames = [\"de/abs_rel\", \"de/sq_rel\", \"de/rms\", \"de/log_rms\", \"da/a1\", \"da/a2\", \"da/a3\"]\n",
    "        self.backprojectDepth = {}\n",
    "        self.project3d = {}\n",
    "        for scale in range(self.numScales):\n",
    "            h = self.height // (2**scale)\n",
    "            w = self.width // (2**scale)\n",
    "            self.backprojectDepth[scale] = BackprojectDepth(self.batchSize, h, w)\n",
    "            self.backprojectDepth[scale] = self.backprojectDepth[scale].to(self.device)\n",
    "            self.project3d[scale] = Project3D(self.batchSize, h, w)\n",
    "            self.project3d[scale] = self.project3d[scale].to(self.device)\n",
    "        self.writers = {}\n",
    "        for mode in [\"train\", \"val\"]:\n",
    "            self.writers[mode] = SummaryWriter(os.path.join(\"/scratch/mp6021/Monodepth2/logs\", mode))\n",
    "\n",
    "    def readlines(self, path):\n",
    "        with open(path, \"r\") as f:\n",
    "            lines = f.read().splitlines()\n",
    "        return lines\n",
    "\n",
    "    def loadDataset(self):\n",
    "        self.dataset = KITTI\n",
    "        dataPath = os.path.join(\"/scratch/mp6021/Monodepth2\", \"data\", \"KITTI\")\n",
    "        filepath = os.path.join(dataPath, \"splits\", \"eigen_zhou\", \"{}_files.txt\")\n",
    "        trainFilenames = self.readlines(filepath.format(\"train\"))\n",
    "        valFilenames = self.readlines(filepath.format(\"val\"))\n",
    "        numTrain = len(trainFilenames)\n",
    "        self.numSteps = numTrain//(self.batchSize*self.epochs)\n",
    "        trainDataset = self.dataset(dataPath, trainFilenames, self.height, self.width,\n",
    "                                    self.frameIdxs, 4, True)\n",
    "        valDataset = self.dataset(dataPath, valFilenames, self.height, self.width, self.frameIdxs,\n",
    "                                  4, False)\n",
    "        self.trainLoader = DataLoader(trainDataset, self.batchSize, shuffle=True, num_workers=14, pin_memory=True, drop_last=True)\n",
    "        self.valLoader = DataLoader(valDataset, self.batchSize, shuffle=False, num_workers=14, pin_memory=True, drop_last=True)\n",
    "        self.valIterator = iter(self.valLoader)\n",
    "\n",
    "    def setTrain(self):\n",
    "        for model in self.models.values():\n",
    "            model.train()\n",
    "\n",
    "    def setEval(self):\n",
    "        for model in self.models.values():\n",
    "            model.eval()\n",
    "            \n",
    "    def log(self, mode, inputs, outputs, losses):\n",
    "        writer = self.writers[mode]\n",
    "        for lossname, value in losses.items():\n",
    "            writer.add_scalar(\"{}\".format(lossname), value, self.step)\n",
    "        for i in range(4):\n",
    "            for scale in range(self.numScales):\n",
    "                for frameIdx in self.frameIdxs:\n",
    "                    writer.add_image(\"color_{}_{}/{}\".format(frameIdx, scale, i), inputs[(\"color\", frameIdx, scale)][i].data, self.step)\n",
    "                    if scale == 0 and frameIdx != 0:\n",
    "                        writer.add_image(\"color_pred_{}_{}/{}\".format(frameIdx, scale, i), outputs[(\"color\", frameIdx, scale)][i].data, self.step)\n",
    "                writer.add_image(\"disp_{}/{}\".format(scale, i), self.normalizeImage(outputs[(\"disp\", scale)][i]), self.step)\n",
    "\n",
    "    def saveModel(self):\n",
    "        outpath = os.path.join(\"/scratch/mp6021/Monodepth2\", \"models\", \"weights_{}\".format(self.epoch))\n",
    "        if not os.path.exists(outpath):\n",
    "            os.makedirs(outpath)\n",
    "        for name, model in self.models.items():\n",
    "            savePath = os.path.join(outpath, \"{}.pth\".format(name))\n",
    "            toSave = model.state_dict()\n",
    "            if name == \"encoder\":\n",
    "                toSave[\"height\"] = self.height\n",
    "                toSave[\"width\"] = self.width\n",
    "            torch.save(toSave, savePath)\n",
    "        savePath = os.path.join(outpath, \"adam.pth\")\n",
    "        torch.save(self.optimizer.state_dict(), savePath)\n",
    "\n",
    "    def normalizeImage(self, image):\n",
    "        maxValue = float(image.max().cpu().data)\n",
    "        minValue = float(image.min().cpu().data)\n",
    "        diff = (maxValue - minValue) if maxValue != minValue else 1e5\n",
    "        return (image - minValue)/diff\n",
    "        \n",
    "    def dispToDepth(self, disp, minDepth, maxDepth):\n",
    "        minDisp = 1 / maxDepth\n",
    "        maxDisp = 1 / minDepth\n",
    "        scaledDisp = minDisp + (maxDisp - minDisp)*disp\n",
    "        depth = 1 / scaledDisp\n",
    "        return scaledDisp, depth\n",
    "\n",
    "    def rotationFromAxisAngle(self, axisangle):\n",
    "        angle = torch.norm(axisangle, 2, 2, True)\n",
    "        axis = axisangle / (angle + 1e-7)\n",
    "        cosAngle = torch.cos(angle)\n",
    "        sinAngle = torch.sin(angle)\n",
    "        complementCos = 1 - cosAngle\n",
    "        x = axis[..., 0].unsqueeze(1)\n",
    "        y = axis[..., 1].unsqueeze(1)\n",
    "        z = axis[..., 2].unsqueeze(1)\n",
    "        xs = x * sinAngle\n",
    "        ys = y * sinAngle\n",
    "        zs = z * sinAngle\n",
    "        xcomplementCos = x * complementCos\n",
    "        ycomplementCos = y * complementCos\n",
    "        zcomplementCos = z * complementCos\n",
    "        xycomplementCos = x * ycomplementCos\n",
    "        yzcomplementCos = y * zcomplementCos\n",
    "        zxcomplementCos = z * xcomplementCos\n",
    "        rot = torch.zeros((axisangle.shape[0], 4, 4)).to(device=axisangle.device)\n",
    "        rot[:, 0, 0] = torch.squeeze(x * xcomplementCos + cosAngle)\n",
    "        rot[:, 0, 1] = torch.squeeze(xycomplementCos - zs)\n",
    "        rot[:, 0, 2] = torch.squeeze(zxcomplementCos + ys)\n",
    "        rot[:, 1, 0] = torch.squeeze(xycomplementCos + zs)\n",
    "        rot[:, 1, 1] = torch.squeeze(y * ycomplementCos + cosAngle)\n",
    "        rot[:, 1, 2] = torch.squeeze(yzcomplementCos - xs)\n",
    "        rot[:, 2, 0] = torch.squeeze(zxcomplementCos - ys)\n",
    "        rot[:, 2, 1] = torch.squeeze(yzcomplementCos + xs)\n",
    "        rot[:, 2, 2] = torch.squeeze(z * zcomplementCos + cosAngle)\n",
    "        rot[:, 3, 3] = 1\n",
    "        return rot\n",
    "\n",
    "    def getTranslationMatrix(self, translation):\n",
    "        T = torch.zeros(translation.shape[0], 4, 4).to(device=translation.device)\n",
    "        t = translation.contiguous().view(-1, 3, 1)\n",
    "        T[:, 0, 0] = 1\n",
    "        T[:, 1, 1] = 1\n",
    "        T[:, 2, 2] = 1\n",
    "        T[:, 3, 3] = 1\n",
    "        T[:, :3, 3, None] = t\n",
    "        return T\n",
    "\n",
    "    def transformParameters(self, axisangle, translation, invert=False):\n",
    "        rotation = self.rotationFromAxisAngle(axisangle)\n",
    "        trans = translation.clone()\n",
    "        if invert:\n",
    "            rotation = rotation.transpose(1, 2)\n",
    "            trans *= -1\n",
    "        T = self.getTranslationMatrix(trans)\n",
    "        if invert:\n",
    "            M = torch.matmul(rotation, T)\n",
    "        else:\n",
    "            M = torch.matmul(T, rotation)\n",
    "        return M\n",
    "\n",
    "    def predictPoses(self, inputs, features):\n",
    "        outputs = {}\n",
    "        poseInputs = torch.cat([inputs[(\"color_aug\", fi, 0)] for fi in self.frameIdxs if fi != \"s\"], 1)\n",
    "        axisangle, translation = self.models[\"pose\"](poseInputs)\n",
    "        for i, fi in enumerate(self.frameIdxs[1:]):\n",
    "            if fi != \"s\":\n",
    "                outputs[(\"axisangle\", 0, fi)] = axisangle\n",
    "                outputs[(\"translation\", 0, fi)] = translation\n",
    "                outputs[(\"cam_T_cam\", 0, fi)] = self.transformParameters(axisangle[:, i], translation[:, i])\n",
    "        return outputs\n",
    "\n",
    "    def generateImagePredictions(self, inputs, outputs):\n",
    "        for scale in range(self.numScales):\n",
    "            disp = outputs[(\"disp\", scale)]\n",
    "            disp = F.interpolate(disp, [self.height, self.width], mode=\"bilinear\",\n",
    "                                 align_corners=False)\n",
    "            sourceScale = 0\n",
    "            _, depth = self.dispToDepth(disp, 0.1, 100.0)\n",
    "            outputs[(\"depth\", 0, scale)] = depth\n",
    "            for i, frameIdx in enumerate(self.frameIdxs[1:]):\n",
    "                T = outputs[(\"cam_T_cam\", 0, frameIdx)]\n",
    "                cameraPoints = self.backprojectDepth[sourceScale](depth, inputs[(\"inv_K\", sourceScale)])\n",
    "                pixelCoordinates = self.project3d[sourceScale](cameraPoints, inputs[(\"K\", sourceScale)], T)\n",
    "                outputs[(\"sample\", frameIdx, scale)] = pixelCoordinates\n",
    "                outputs[(\"color\", frameIdx, scale)] = F.grid_sample(inputs[(\"color\", frameIdx, sourceScale)],\n",
    "                                                                    outputs[((\"sample\", frameIdx, scale))],\n",
    "                                                                    padding_mode=\"border\")\n",
    "\n",
    "    def computeDepthErrors(self, depthGroundTruth, depthPred):\n",
    "        threshold = torch.max((depthGroundTruth/depthPred), (depthPred/depthGroundTruth))\n",
    "        a1 = (threshold < 1.25).float().mean()\n",
    "        a2 = (threshold < 1.25**2).float().mean()\n",
    "        a3 = (threshold < 1.25**3).float().mean()\n",
    "        rootMeanSquaredError = (depthGroundTruth - depthPred)**2\n",
    "        rootMeanSquaredError = torch.sqrt(rootMeanSquaredError.mean())\n",
    "        rootMeanSquaredErrorLog = (torch.log(depthGroundTruth) - torch.log(depthPred))**2\n",
    "        rootMeanSquaredErrorLog = torch.sqrt(rootMeanSquaredErrorLog.mean())\n",
    "        absolute = torch.mean(torch.abs(depthGroundTruth - depthPred)/depthGroundTruth)\n",
    "        squared = torch.mean(((depthGroundTruth - depthPred)**2)/depthGroundTruth)\n",
    "        return absolute, squared, rootMeanSquaredError, rootMeanSquaredErrorLog, a1, a2, a3\n",
    "\n",
    "    def computeDepthLosses(self, inputs, outputs, losses):\n",
    "        depthPred = outputs[(\"depth\", 0, 0)]\n",
    "        depthPred = torch.clamp(F.interpolate(depthPred, [375, 1242], mode='bilinear',\n",
    "                                              align_corners=False), 1e-3, 80)\n",
    "        depthPred = depthPred.detach()\n",
    "        depthGroundTruth = inputs[\"depth_gt\"]\n",
    "        mask = depthGroundTruth > 0\n",
    "        cropMask = torch.zeros_like(mask)\n",
    "        cropMask[:, :, 153:371, 44:1197] = 1\n",
    "        mask = mask * cropMask\n",
    "        depthGroundTruth = depthGroundTruth[mask]\n",
    "        depthPred = depthPred[mask]\n",
    "        depthPred *= torch.median(depthGroundTruth)/torch.median(depthPred)\n",
    "        depthPred = torch.clamp(depthPred, 1e-3, 80)\n",
    "        depthErrors = self.computeDepthErrors(depthGroundTruth, depthPred)\n",
    "        for i, name in enumerate(self.depthMetricNames):\n",
    "            losses[name] = np.array(depthErrors[i].cpu())\n",
    "\n",
    "    def computeReprojectionLoss(self, pred, target):\n",
    "        absDiff = torch.abs(pred - target)\n",
    "        l1Loss = absDiff.mean(1, True)\n",
    "        return l1Loss\n",
    "\n",
    "    def getSmoothLoss(self, disp, img):\n",
    "        gradientDispX = torch.abs(disp[:, :, :, :-1] - disp[:, :, :, 1:])\n",
    "        gradientDispY = torch.abs(disp[:, :, :-1, :] - disp[:, :, 1:, :])\n",
    "        gradientImgX = torch.mean(torch.abs(img[:, :, :, :-1] - img[:, :, :, 1:]), 1, keepdim=True)\n",
    "        gradientImgY = torch.mean(torch.abs(img[:, :, :-1, :] - img[:, :, 1:, :]), 1, keepdim=True)\n",
    "        gradientDispX *= torch.exp(-gradientImgX)\n",
    "        gradientDispY *= torch.exp(-gradientImgY)\n",
    "        return gradientDispX.mean() + gradientDispY.mean()\n",
    "\n",
    "    def computeLosses(self, inputs, outputs):\n",
    "        losses = {}\n",
    "        totalLoss = 0\n",
    "        for scale in range(self.numScales):\n",
    "            loss = 0\n",
    "            reprojectionLoss = []\n",
    "            sourceScale = 0\n",
    "            disp = outputs[(\"disp\", scale)]\n",
    "            color = inputs[(\"color\", 0, scale)]\n",
    "            target = inputs[(\"color\", 0, sourceScale)]\n",
    "            for frameIdx in self.frameIdxs[1:]:\n",
    "                pred = outputs[(\"color\", frameIdx, scale)]\n",
    "                reprojectionLoss.append(self.computeReprojectionLoss(pred, target))\n",
    "            reprojectionLoss = torch.cat(reprojectionLoss, 1)\n",
    "            combined = reprojectionLoss\n",
    "            if combined.shape[1] == 1:\n",
    "                toOptimise = combined\n",
    "            else:\n",
    "                toOptimise, idxs = torch.min(combined, dim=1)\n",
    "            loss += toOptimise.mean()\n",
    "            meanDisp = disp.mean(2, True).mean(3, True)\n",
    "            normDisp = disp / (meanDisp + 1e-7)\n",
    "            smoothLoss = self.getSmoothLoss(normDisp, color)\n",
    "            loss += (1e-3 * smoothLoss)/(2**scale)\n",
    "            totalLoss += loss\n",
    "            losses[\"loss/{}\".format(scale)] = loss\n",
    "        totalLoss /= self.numScales\n",
    "        losses[\"loss\"] = totalLoss\n",
    "        return losses\n",
    "\n",
    "    def processBatch(self, inputs):\n",
    "        for key, value in inputs.items():\n",
    "            inputs[key] = value.to(self.device)\n",
    "        features = self.models[\"encoder\"](inputs[\"color_aug\", 0, 0])\n",
    "        outputs = self.models[\"decoder\"](features)\n",
    "        outputs.update(self.predictPoses(inputs, features))\n",
    "        self.generateImagePredictions(inputs, outputs)\n",
    "        losses = self.computeLosses(inputs, outputs)\n",
    "        return outputs, losses\n",
    "\n",
    "    def runEpoch(self):\n",
    "        self.lrScheduler.step()\n",
    "        self.setTrain()\n",
    "        for batchIdx, inputs in enumerate(self.trainLoader):\n",
    "            outputs, losses = self.processBatch(inputs)\n",
    "            self.optimizer.zero_grad()\n",
    "            losses[\"loss\"].backward()\n",
    "            self.optimizer.step()\n",
    "            self.computeDepthLosses(inputs, outputs, losses)\n",
    "            self.log(\"train\", inputs, outputs, losses)\n",
    "            print(\"Epoch : {}, Batch : {}, Loss : {}\".format(self.epoch, batchIdx, losses[\"loss\"].item()))\n",
    "            self.val()\n",
    "            self.step += 1\n",
    "\n",
    "    def train(self):\n",
    "        self.epoch = 0\n",
    "        self.step = 0\n",
    "        for self.epoch in range(self.epochs):\n",
    "            print(\"Training --- Epoch : {}\".format(self.epoch))\n",
    "            self.runEpoch()\n",
    "            if self.epoch % 5 == 0:\n",
    "                self.saveModel()\n",
    "\n",
    "    def val(self):\n",
    "        self.setEval()\n",
    "        try:\n",
    "            inputs = self.valIterator.next()\n",
    "        except:\n",
    "            self.valIterator = iter(self.valLoader)\n",
    "            inputs = self.valIterator.next()\n",
    "        with torch.no_grad():\n",
    "            outputs, losses = self.processBatch(inputs)\n",
    "            self.computeDepthLosses(inputs, outputs, losses)\n",
    "            self.log(\"val\", inputs, outputs, losses)\n",
    "            del inputs, outputs, losses\n",
    "        self.setTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "t = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training --- Epoch : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp6021/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/mp6021/.local/lib/python3.8/site-packages/torch/nn/functional.py:4193: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 0, Loss : 0.05104696378111839\n",
      "Epoch : 0, Batch : 1, Loss : 0.058854881674051285\n",
      "Epoch : 0, Batch : 2, Loss : 0.049349185079336166\n",
      "Epoch : 0, Batch : 3, Loss : 0.05502218380570412\n",
      "Epoch : 0, Batch : 4, Loss : 0.047446995973587036\n",
      "Epoch : 0, Batch : 5, Loss : 0.04906464368104935\n",
      "Epoch : 0, Batch : 6, Loss : 0.05254996195435524\n",
      "Epoch : 0, Batch : 7, Loss : 0.05421455577015877\n",
      "Epoch : 0, Batch : 8, Loss : 0.046916645020246506\n",
      "Epoch : 0, Batch : 9, Loss : 0.050739213824272156\n",
      "Epoch : 0, Batch : 10, Loss : 0.057883121073246\n",
      "Epoch : 0, Batch : 11, Loss : 0.04876068979501724\n",
      "Epoch : 0, Batch : 12, Loss : 0.061506349593400955\n",
      "Epoch : 0, Batch : 13, Loss : 0.04958373308181763\n",
      "Epoch : 0, Batch : 14, Loss : 0.0468829907476902\n",
      "Epoch : 0, Batch : 15, Loss : 0.05680917948484421\n",
      "Epoch : 0, Batch : 16, Loss : 0.053914252668619156\n",
      "Epoch : 0, Batch : 17, Loss : 0.05194557085633278\n",
      "Epoch : 0, Batch : 18, Loss : 0.05788726359605789\n",
      "Epoch : 0, Batch : 19, Loss : 0.04778522998094559\n",
      "Epoch : 0, Batch : 20, Loss : 0.04669385403394699\n",
      "Epoch : 0, Batch : 21, Loss : 0.051537517458200455\n",
      "Epoch : 0, Batch : 22, Loss : 0.04700089618563652\n",
      "Epoch : 0, Batch : 23, Loss : 0.051710039377212524\n",
      "Epoch : 0, Batch : 24, Loss : 0.04956445097923279\n",
      "Epoch : 0, Batch : 25, Loss : 0.05651026591658592\n",
      "Epoch : 0, Batch : 26, Loss : 0.05565878003835678\n",
      "Epoch : 0, Batch : 27, Loss : 0.055324625223875046\n",
      "Epoch : 0, Batch : 28, Loss : 0.053666986525058746\n",
      "Epoch : 0, Batch : 29, Loss : 0.05050979182124138\n",
      "Epoch : 0, Batch : 30, Loss : 0.04731644317507744\n",
      "Epoch : 0, Batch : 31, Loss : 0.05321488529443741\n",
      "Epoch : 0, Batch : 32, Loss : 0.04906747490167618\n",
      "Epoch : 0, Batch : 33, Loss : 0.046389948576688766\n",
      "Epoch : 0, Batch : 34, Loss : 0.04269859939813614\n",
      "Epoch : 0, Batch : 35, Loss : 0.05532507598400116\n",
      "Epoch : 0, Batch : 36, Loss : 0.04892611503601074\n",
      "Epoch : 0, Batch : 37, Loss : 0.04421546682715416\n",
      "Epoch : 0, Batch : 38, Loss : 0.04477323591709137\n",
      "Epoch : 0, Batch : 39, Loss : 0.049788765609264374\n",
      "Epoch : 0, Batch : 40, Loss : 0.05090256780385971\n",
      "Epoch : 0, Batch : 41, Loss : 0.04740910604596138\n",
      "Epoch : 0, Batch : 42, Loss : 0.05155298113822937\n",
      "Epoch : 0, Batch : 43, Loss : 0.04739445075392723\n",
      "Epoch : 0, Batch : 44, Loss : 0.04683426767587662\n",
      "Epoch : 0, Batch : 45, Loss : 0.05329461023211479\n",
      "Epoch : 0, Batch : 46, Loss : 0.04175263270735741\n",
      "Epoch : 0, Batch : 47, Loss : 0.05192045122385025\n",
      "Epoch : 0, Batch : 48, Loss : 0.04214249551296234\n",
      "Epoch : 0, Batch : 49, Loss : 0.05436517670750618\n",
      "Epoch : 0, Batch : 50, Loss : 0.05403666943311691\n",
      "Epoch : 0, Batch : 51, Loss : 0.048166126012802124\n",
      "Epoch : 0, Batch : 52, Loss : 0.05303087830543518\n",
      "Epoch : 0, Batch : 53, Loss : 0.05325118452310562\n",
      "Epoch : 0, Batch : 54, Loss : 0.04671534150838852\n",
      "Epoch : 0, Batch : 55, Loss : 0.05209635943174362\n",
      "Epoch : 0, Batch : 56, Loss : 0.051307834684848785\n",
      "Epoch : 0, Batch : 57, Loss : 0.05592323839664459\n",
      "Epoch : 0, Batch : 58, Loss : 0.0533953458070755\n",
      "Epoch : 0, Batch : 59, Loss : 0.053288571536540985\n",
      "Epoch : 0, Batch : 60, Loss : 0.049541451036930084\n",
      "Epoch : 0, Batch : 61, Loss : 0.055278677493333817\n",
      "Epoch : 0, Batch : 62, Loss : 0.047200869768857956\n",
      "Epoch : 0, Batch : 63, Loss : 0.045674391090869904\n",
      "Epoch : 0, Batch : 64, Loss : 0.04897870868444443\n",
      "Epoch : 0, Batch : 65, Loss : 0.04087933897972107\n",
      "Epoch : 0, Batch : 66, Loss : 0.04459531605243683\n",
      "Epoch : 0, Batch : 67, Loss : 0.04961927980184555\n",
      "Epoch : 0, Batch : 68, Loss : 0.050768084824085236\n",
      "Epoch : 0, Batch : 69, Loss : 0.052444711327552795\n",
      "Epoch : 0, Batch : 70, Loss : 0.04758719727396965\n",
      "Epoch : 0, Batch : 71, Loss : 0.055693138390779495\n",
      "Epoch : 0, Batch : 72, Loss : 0.05461735650897026\n",
      "Epoch : 0, Batch : 73, Loss : 0.05038110911846161\n",
      "Epoch : 0, Batch : 74, Loss : 0.05564982071518898\n",
      "Epoch : 0, Batch : 75, Loss : 0.04251336306333542\n",
      "Epoch : 0, Batch : 76, Loss : 0.05225110426545143\n",
      "Epoch : 0, Batch : 77, Loss : 0.05005504935979843\n",
      "Epoch : 0, Batch : 78, Loss : 0.053192347288131714\n",
      "Epoch : 0, Batch : 79, Loss : 0.051948606967926025\n",
      "Epoch : 0, Batch : 80, Loss : 0.0456891730427742\n",
      "Epoch : 0, Batch : 81, Loss : 0.04880908131599426\n",
      "Epoch : 0, Batch : 82, Loss : 0.046467967331409454\n",
      "Epoch : 0, Batch : 83, Loss : 0.05629178136587143\n",
      "Epoch : 0, Batch : 84, Loss : 0.04842840135097504\n",
      "Epoch : 0, Batch : 85, Loss : 0.050911128520965576\n",
      "Epoch : 0, Batch : 86, Loss : 0.05327438563108444\n",
      "Epoch : 0, Batch : 87, Loss : 0.05029851198196411\n",
      "Epoch : 0, Batch : 88, Loss : 0.051873233169317245\n",
      "Epoch : 0, Batch : 89, Loss : 0.058885157108306885\n",
      "Epoch : 0, Batch : 90, Loss : 0.047373924404382706\n",
      "Epoch : 0, Batch : 91, Loss : 0.05478474870324135\n",
      "Epoch : 0, Batch : 92, Loss : 0.04099113121628761\n",
      "Epoch : 0, Batch : 93, Loss : 0.05168044567108154\n",
      "Epoch : 0, Batch : 94, Loss : 0.05973070487380028\n",
      "Epoch : 0, Batch : 95, Loss : 0.04648208990693092\n",
      "Epoch : 0, Batch : 96, Loss : 0.04795122891664505\n",
      "Epoch : 0, Batch : 97, Loss : 0.045754559338092804\n",
      "Epoch : 0, Batch : 98, Loss : 0.04744483530521393\n",
      "Epoch : 0, Batch : 99, Loss : 0.05121588334441185\n",
      "Epoch : 0, Batch : 100, Loss : 0.05322510004043579\n",
      "Epoch : 0, Batch : 101, Loss : 0.058258943259716034\n",
      "Epoch : 0, Batch : 102, Loss : 0.05471186339855194\n",
      "Epoch : 0, Batch : 103, Loss : 0.06109430640935898\n",
      "Epoch : 0, Batch : 104, Loss : 0.048461560159921646\n",
      "Epoch : 0, Batch : 105, Loss : 0.046228569000959396\n",
      "Epoch : 0, Batch : 106, Loss : 0.042583756148815155\n",
      "Epoch : 0, Batch : 107, Loss : 0.04853707179427147\n",
      "Epoch : 0, Batch : 108, Loss : 0.05302540957927704\n",
      "Epoch : 0, Batch : 109, Loss : 0.04211341589689255\n",
      "Epoch : 0, Batch : 110, Loss : 0.050697654485702515\n",
      "Epoch : 0, Batch : 111, Loss : 0.04487237706780434\n",
      "Epoch : 0, Batch : 112, Loss : 0.0532047376036644\n",
      "Epoch : 0, Batch : 113, Loss : 0.05009066313505173\n",
      "Epoch : 0, Batch : 114, Loss : 0.05382418632507324\n",
      "Epoch : 0, Batch : 115, Loss : 0.04902341589331627\n",
      "Epoch : 0, Batch : 116, Loss : 0.048242829740047455\n",
      "Epoch : 0, Batch : 117, Loss : 0.0506894588470459\n",
      "Epoch : 0, Batch : 118, Loss : 0.05475859344005585\n",
      "Epoch : 0, Batch : 119, Loss : 0.04914827644824982\n",
      "Epoch : 0, Batch : 120, Loss : 0.05321425944566727\n",
      "Epoch : 0, Batch : 121, Loss : 0.049609191715717316\n",
      "Epoch : 0, Batch : 122, Loss : 0.048656001687049866\n",
      "Epoch : 0, Batch : 123, Loss : 0.0531347282230854\n",
      "Epoch : 0, Batch : 124, Loss : 0.05028931051492691\n",
      "Epoch : 0, Batch : 125, Loss : 0.05001744627952576\n",
      "Epoch : 0, Batch : 126, Loss : 0.050709743052721024\n",
      "Epoch : 0, Batch : 127, Loss : 0.0456196665763855\n",
      "Epoch : 0, Batch : 128, Loss : 0.046780459582805634\n",
      "Epoch : 0, Batch : 129, Loss : 0.04697611182928085\n",
      "Epoch : 0, Batch : 130, Loss : 0.048762790858745575\n",
      "Epoch : 0, Batch : 131, Loss : 0.04801509529352188\n",
      "Epoch : 0, Batch : 132, Loss : 0.05174858123064041\n",
      "Epoch : 0, Batch : 133, Loss : 0.058224961161613464\n",
      "Epoch : 0, Batch : 134, Loss : 0.04754437506198883\n",
      "Epoch : 0, Batch : 135, Loss : 0.05071213096380234\n",
      "Epoch : 0, Batch : 136, Loss : 0.05227959156036377\n",
      "Epoch : 0, Batch : 137, Loss : 0.055213190615177155\n",
      "Epoch : 0, Batch : 138, Loss : 0.05729132890701294\n",
      "Epoch : 0, Batch : 139, Loss : 0.053947292268276215\n",
      "Epoch : 0, Batch : 140, Loss : 0.05859191715717316\n",
      "Epoch : 0, Batch : 141, Loss : 0.047389786690473557\n",
      "Epoch : 0, Batch : 142, Loss : 0.05482011288404465\n",
      "Epoch : 0, Batch : 143, Loss : 0.048570416867733\n",
      "Epoch : 0, Batch : 144, Loss : 0.060888566076755524\n",
      "Epoch : 0, Batch : 145, Loss : 0.04831336811184883\n",
      "Epoch : 0, Batch : 146, Loss : 0.055217575281858444\n",
      "Epoch : 0, Batch : 147, Loss : 0.04723659157752991\n",
      "Epoch : 0, Batch : 148, Loss : 0.05365544557571411\n",
      "Epoch : 0, Batch : 149, Loss : 0.05313336104154587\n",
      "Epoch : 0, Batch : 150, Loss : 0.04643160104751587\n",
      "Epoch : 0, Batch : 151, Loss : 0.04574237018823624\n",
      "Epoch : 0, Batch : 152, Loss : 0.04520255699753761\n",
      "Epoch : 0, Batch : 153, Loss : 0.053297605365514755\n",
      "Epoch : 0, Batch : 154, Loss : 0.05055515468120575\n",
      "Epoch : 0, Batch : 155, Loss : 0.0511944480240345\n",
      "Epoch : 0, Batch : 156, Loss : 0.046440474689006805\n",
      "Epoch : 0, Batch : 157, Loss : 0.049005456268787384\n",
      "Epoch : 0, Batch : 158, Loss : 0.051625028252601624\n",
      "Epoch : 0, Batch : 159, Loss : 0.05293882265686989\n",
      "Epoch : 0, Batch : 160, Loss : 0.04419941455125809\n",
      "Epoch : 0, Batch : 161, Loss : 0.04570206254720688\n",
      "Epoch : 0, Batch : 162, Loss : 0.06123749911785126\n",
      "Epoch : 0, Batch : 163, Loss : 0.05629768222570419\n",
      "Epoch : 0, Batch : 164, Loss : 0.05529038608074188\n",
      "Epoch : 0, Batch : 165, Loss : 0.0509735643863678\n",
      "Epoch : 0, Batch : 166, Loss : 0.05053985118865967\n",
      "Epoch : 0, Batch : 167, Loss : 0.052435651421546936\n",
      "Epoch : 0, Batch : 168, Loss : 0.053117863833904266\n",
      "Epoch : 0, Batch : 169, Loss : 0.046070680022239685\n",
      "Epoch : 0, Batch : 170, Loss : 0.048836831003427505\n",
      "Epoch : 0, Batch : 171, Loss : 0.05136738717556\n",
      "Epoch : 0, Batch : 172, Loss : 0.04957146197557449\n",
      "Epoch : 0, Batch : 173, Loss : 0.05552522838115692\n",
      "Epoch : 0, Batch : 174, Loss : 0.039984047412872314\n",
      "Epoch : 0, Batch : 175, Loss : 0.05338083952665329\n",
      "Epoch : 0, Batch : 176, Loss : 0.06023716926574707\n",
      "Epoch : 0, Batch : 177, Loss : 0.050090715289115906\n",
      "Epoch : 0, Batch : 178, Loss : 0.044897377490997314\n",
      "Epoch : 0, Batch : 179, Loss : 0.053624227643013\n",
      "Epoch : 0, Batch : 180, Loss : 0.0524216964840889\n",
      "Epoch : 0, Batch : 181, Loss : 0.0572318509221077\n",
      "Epoch : 0, Batch : 182, Loss : 0.053180329501628876\n",
      "Epoch : 0, Batch : 183, Loss : 0.052981771528720856\n",
      "Epoch : 0, Batch : 184, Loss : 0.04678698629140854\n",
      "Epoch : 0, Batch : 185, Loss : 0.048203982412815094\n",
      "Epoch : 0, Batch : 186, Loss : 0.06067153066396713\n",
      "Epoch : 0, Batch : 187, Loss : 0.04874398559331894\n",
      "Epoch : 0, Batch : 188, Loss : 0.0493890717625618\n",
      "Epoch : 0, Batch : 189, Loss : 0.04720834642648697\n",
      "Epoch : 0, Batch : 190, Loss : 0.048445820808410645\n",
      "Epoch : 0, Batch : 191, Loss : 0.053995754569768906\n",
      "Epoch : 0, Batch : 192, Loss : 0.04759740084409714\n",
      "Epoch : 0, Batch : 193, Loss : 0.04794083535671234\n",
      "Epoch : 0, Batch : 194, Loss : 0.06252406537532806\n",
      "Epoch : 0, Batch : 195, Loss : 0.04609382897615433\n",
      "Epoch : 0, Batch : 196, Loss : 0.05819999799132347\n",
      "Epoch : 0, Batch : 197, Loss : 0.05583760142326355\n",
      "Epoch : 0, Batch : 198, Loss : 0.04776348918676376\n",
      "Epoch : 0, Batch : 199, Loss : 0.04552840441465378\n",
      "Epoch : 0, Batch : 200, Loss : 0.05820021778345108\n",
      "Epoch : 0, Batch : 201, Loss : 0.053527768701314926\n",
      "Epoch : 0, Batch : 202, Loss : 0.051738932728767395\n",
      "Epoch : 0, Batch : 203, Loss : 0.05766688287258148\n",
      "Epoch : 0, Batch : 204, Loss : 0.05005626380443573\n",
      "Epoch : 0, Batch : 205, Loss : 0.05847863852977753\n",
      "Epoch : 0, Batch : 206, Loss : 0.05495363473892212\n",
      "Epoch : 0, Batch : 207, Loss : 0.0456271655857563\n",
      "Epoch : 0, Batch : 208, Loss : 0.04592400789260864\n",
      "Epoch : 0, Batch : 209, Loss : 0.05384623259305954\n",
      "Epoch : 0, Batch : 210, Loss : 0.04989399015903473\n",
      "Epoch : 0, Batch : 211, Loss : 0.04441002011299133\n",
      "Epoch : 0, Batch : 212, Loss : 0.04780251532793045\n",
      "Epoch : 0, Batch : 213, Loss : 0.04476776346564293\n",
      "Epoch : 0, Batch : 214, Loss : 0.053446777164936066\n",
      "Epoch : 0, Batch : 215, Loss : 0.046437352895736694\n",
      "Epoch : 0, Batch : 216, Loss : 0.05658084154129028\n",
      "Epoch : 0, Batch : 217, Loss : 0.05729179456830025\n",
      "Epoch : 0, Batch : 218, Loss : 0.06217193976044655\n",
      "Epoch : 0, Batch : 219, Loss : 0.04792628809809685\n",
      "Epoch : 0, Batch : 220, Loss : 0.04883083701133728\n",
      "Epoch : 0, Batch : 221, Loss : 0.05563484504818916\n",
      "Epoch : 0, Batch : 222, Loss : 0.055115021765232086\n",
      "Epoch : 0, Batch : 223, Loss : 0.05159109830856323\n",
      "Epoch : 0, Batch : 224, Loss : 0.05111144483089447\n",
      "Epoch : 0, Batch : 225, Loss : 0.05033540725708008\n",
      "Epoch : 0, Batch : 226, Loss : 0.05157151818275452\n",
      "Epoch : 0, Batch : 227, Loss : 0.05227835848927498\n",
      "Epoch : 0, Batch : 228, Loss : 0.05313915014266968\n",
      "Epoch : 0, Batch : 229, Loss : 0.04466641694307327\n",
      "Epoch : 0, Batch : 230, Loss : 0.05213303491473198\n",
      "Epoch : 0, Batch : 231, Loss : 0.04836464673280716\n",
      "Epoch : 0, Batch : 232, Loss : 0.045530784875154495\n",
      "Epoch : 0, Batch : 233, Loss : 0.04760926961898804\n",
      "Epoch : 0, Batch : 234, Loss : 0.05169450864195824\n",
      "Epoch : 0, Batch : 235, Loss : 0.04718172550201416\n",
      "Epoch : 0, Batch : 236, Loss : 0.04562626779079437\n",
      "Epoch : 0, Batch : 237, Loss : 0.044056277722120285\n",
      "Epoch : 0, Batch : 238, Loss : 0.05922529101371765\n",
      "Epoch : 0, Batch : 239, Loss : 0.048239484429359436\n",
      "Epoch : 0, Batch : 240, Loss : 0.0557979978621006\n",
      "Epoch : 0, Batch : 241, Loss : 0.05741497874259949\n",
      "Epoch : 0, Batch : 242, Loss : 0.04816524684429169\n",
      "Epoch : 0, Batch : 243, Loss : 0.04962434619665146\n",
      "Epoch : 0, Batch : 244, Loss : 0.05301188305020332\n",
      "Epoch : 0, Batch : 245, Loss : 0.052098050713539124\n",
      "Epoch : 0, Batch : 246, Loss : 0.04749026894569397\n",
      "Epoch : 0, Batch : 247, Loss : 0.056061115115880966\n",
      "Epoch : 0, Batch : 248, Loss : 0.04812496900558472\n",
      "Epoch : 0, Batch : 249, Loss : 0.044728800654411316\n",
      "Epoch : 0, Batch : 250, Loss : 0.048730526119470596\n",
      "Epoch : 0, Batch : 251, Loss : 0.04979826509952545\n",
      "Epoch : 0, Batch : 252, Loss : 0.04950921982526779\n",
      "Epoch : 0, Batch : 253, Loss : 0.04596186429262161\n",
      "Epoch : 0, Batch : 254, Loss : 0.05560080707073212\n",
      "Epoch : 0, Batch : 255, Loss : 0.050361230969429016\n",
      "Epoch : 0, Batch : 256, Loss : 0.04601854085922241\n",
      "Epoch : 0, Batch : 257, Loss : 0.050536178052425385\n",
      "Epoch : 0, Batch : 258, Loss : 0.046110235154628754\n",
      "Epoch : 0, Batch : 259, Loss : 0.04923377186059952\n",
      "Epoch : 0, Batch : 260, Loss : 0.054170623421669006\n",
      "Epoch : 0, Batch : 261, Loss : 0.05399692803621292\n",
      "Epoch : 0, Batch : 262, Loss : 0.048184581100940704\n",
      "Epoch : 0, Batch : 263, Loss : 0.058968402445316315\n",
      "Epoch : 0, Batch : 264, Loss : 0.04645494744181633\n",
      "Epoch : 0, Batch : 265, Loss : 0.046913061290979385\n",
      "Epoch : 0, Batch : 266, Loss : 0.05287767946720123\n",
      "Epoch : 0, Batch : 267, Loss : 0.04645819962024689\n",
      "Epoch : 0, Batch : 268, Loss : 0.05102914571762085\n",
      "Epoch : 0, Batch : 269, Loss : 0.058825474232435226\n",
      "Epoch : 0, Batch : 270, Loss : 0.04142072796821594\n",
      "Epoch : 0, Batch : 271, Loss : 0.04340531304478645\n",
      "Epoch : 0, Batch : 272, Loss : 0.06275320053100586\n",
      "Epoch : 0, Batch : 273, Loss : 0.05007053166627884\n",
      "Epoch : 0, Batch : 274, Loss : 0.052334822714328766\n",
      "Epoch : 0, Batch : 275, Loss : 0.043396398425102234\n",
      "Epoch : 0, Batch : 276, Loss : 0.05254731327295303\n",
      "Epoch : 0, Batch : 277, Loss : 0.05201112478971481\n",
      "Epoch : 0, Batch : 278, Loss : 0.042772192507982254\n",
      "Epoch : 0, Batch : 279, Loss : 0.05005329102277756\n",
      "Epoch : 0, Batch : 280, Loss : 0.04800545796751976\n",
      "Epoch : 0, Batch : 281, Loss : 0.03763141483068466\n",
      "Epoch : 0, Batch : 282, Loss : 0.04982166737318039\n",
      "Epoch : 0, Batch : 283, Loss : 0.05167223513126373\n",
      "Epoch : 0, Batch : 284, Loss : 0.050957053899765015\n",
      "Epoch : 0, Batch : 285, Loss : 0.05868610739707947\n",
      "Epoch : 0, Batch : 286, Loss : 0.05896264314651489\n",
      "Epoch : 0, Batch : 287, Loss : 0.05285133421421051\n",
      "Epoch : 0, Batch : 288, Loss : 0.050302378833293915\n",
      "Epoch : 0, Batch : 289, Loss : 0.04615054279565811\n",
      "Epoch : 0, Batch : 290, Loss : 0.048031918704509735\n",
      "Epoch : 0, Batch : 291, Loss : 0.04664437472820282\n",
      "Epoch : 0, Batch : 292, Loss : 0.05114898830652237\n",
      "Epoch : 0, Batch : 293, Loss : 0.04665052145719528\n",
      "Epoch : 0, Batch : 294, Loss : 0.04824609309434891\n",
      "Epoch : 0, Batch : 295, Loss : 0.04892633110284805\n",
      "Epoch : 0, Batch : 296, Loss : 0.05234283581376076\n",
      "Epoch : 0, Batch : 297, Loss : 0.06098930537700653\n",
      "Epoch : 0, Batch : 298, Loss : 0.043594636023044586\n",
      "Epoch : 0, Batch : 299, Loss : 0.04893207922577858\n",
      "Epoch : 0, Batch : 300, Loss : 0.061358287930488586\n",
      "Epoch : 0, Batch : 301, Loss : 0.040373869240283966\n",
      "Epoch : 0, Batch : 302, Loss : 0.05553004890680313\n",
      "Epoch : 0, Batch : 303, Loss : 0.04387787729501724\n",
      "Epoch : 0, Batch : 304, Loss : 0.04956913739442825\n",
      "Epoch : 0, Batch : 305, Loss : 0.04582097381353378\n",
      "Epoch : 0, Batch : 306, Loss : 0.04751570522785187\n",
      "Epoch : 0, Batch : 307, Loss : 0.05302910506725311\n",
      "Epoch : 0, Batch : 308, Loss : 0.05005088075995445\n",
      "Epoch : 0, Batch : 309, Loss : 0.04518761485815048\n",
      "Epoch : 0, Batch : 310, Loss : 0.048996731638908386\n",
      "Epoch : 0, Batch : 311, Loss : 0.04694763943552971\n",
      "Epoch : 0, Batch : 312, Loss : 0.046073801815509796\n",
      "Epoch : 0, Batch : 313, Loss : 0.04775149002671242\n",
      "Epoch : 0, Batch : 314, Loss : 0.043833278119564056\n",
      "Epoch : 0, Batch : 315, Loss : 0.04922943562269211\n",
      "Epoch : 0, Batch : 316, Loss : 0.050353165715932846\n",
      "Epoch : 0, Batch : 317, Loss : 0.044295914471149445\n",
      "Epoch : 0, Batch : 318, Loss : 0.054244957864284515\n",
      "Epoch : 0, Batch : 319, Loss : 0.04765092954039574\n",
      "Epoch : 0, Batch : 320, Loss : 0.04419168084859848\n",
      "Epoch : 0, Batch : 321, Loss : 0.049909088760614395\n",
      "Epoch : 0, Batch : 322, Loss : 0.054484233260154724\n",
      "Epoch : 0, Batch : 323, Loss : 0.04893875867128372\n",
      "Epoch : 0, Batch : 324, Loss : 0.0510888546705246\n",
      "Epoch : 0, Batch : 325, Loss : 0.05053069442510605\n",
      "Epoch : 0, Batch : 326, Loss : 0.05026160180568695\n",
      "Epoch : 0, Batch : 327, Loss : 0.06465261429548264\n",
      "Epoch : 0, Batch : 328, Loss : 0.05843789875507355\n",
      "Epoch : 0, Batch : 329, Loss : 0.04793200641870499\n",
      "Epoch : 0, Batch : 330, Loss : 0.049570802599191666\n",
      "Epoch : 0, Batch : 331, Loss : 0.04583241045475006\n",
      "Epoch : 0, Batch : 332, Loss : 0.04467567801475525\n",
      "Epoch : 0, Batch : 333, Loss : 0.05089785158634186\n",
      "Epoch : 0, Batch : 334, Loss : 0.05574371665716171\n",
      "Epoch : 0, Batch : 335, Loss : 0.048709623515605927\n",
      "Epoch : 0, Batch : 336, Loss : 0.04856225475668907\n",
      "Epoch : 0, Batch : 337, Loss : 0.046234600245952606\n",
      "Epoch : 0, Batch : 338, Loss : 0.05071251839399338\n",
      "Epoch : 0, Batch : 339, Loss : 0.04982547461986542\n",
      "Epoch : 0, Batch : 340, Loss : 0.048966556787490845\n",
      "Epoch : 0, Batch : 341, Loss : 0.04521043971180916\n",
      "Epoch : 0, Batch : 342, Loss : 0.04664966091513634\n",
      "Epoch : 0, Batch : 343, Loss : 0.05211135372519493\n",
      "Epoch : 0, Batch : 344, Loss : 0.05366876721382141\n",
      "Epoch : 0, Batch : 345, Loss : 0.05268560349941254\n",
      "Epoch : 0, Batch : 346, Loss : 0.0468410849571228\n",
      "Epoch : 0, Batch : 347, Loss : 0.05233070254325867\n",
      "Epoch : 0, Batch : 348, Loss : 0.0506865531206131\n",
      "Epoch : 0, Batch : 349, Loss : 0.045975543558597565\n",
      "Epoch : 0, Batch : 350, Loss : 0.05528032407164574\n",
      "Epoch : 0, Batch : 351, Loss : 0.04871843755245209\n",
      "Epoch : 0, Batch : 352, Loss : 0.057464659214019775\n",
      "Epoch : 0, Batch : 353, Loss : 0.04388408735394478\n",
      "Epoch : 0, Batch : 354, Loss : 0.05640580505132675\n",
      "Epoch : 0, Batch : 355, Loss : 0.05733208358287811\n",
      "Epoch : 0, Batch : 356, Loss : 0.05428290367126465\n",
      "Epoch : 0, Batch : 357, Loss : 0.04754488170146942\n",
      "Epoch : 0, Batch : 358, Loss : 0.048933058977127075\n",
      "Epoch : 0, Batch : 359, Loss : 0.053025443106889725\n",
      "Epoch : 0, Batch : 360, Loss : 0.0570451058447361\n",
      "Epoch : 0, Batch : 361, Loss : 0.04857946187257767\n",
      "Epoch : 0, Batch : 362, Loss : 0.05061688274145126\n",
      "Epoch : 0, Batch : 363, Loss : 0.052833590656518936\n",
      "Epoch : 0, Batch : 364, Loss : 0.05193478986620903\n",
      "Epoch : 0, Batch : 365, Loss : 0.0472358837723732\n",
      "Epoch : 0, Batch : 366, Loss : 0.05495847761631012\n",
      "Epoch : 0, Batch : 367, Loss : 0.05231019854545593\n",
      "Epoch : 0, Batch : 368, Loss : 0.05620558187365532\n",
      "Epoch : 0, Batch : 369, Loss : 0.05968273803591728\n",
      "Epoch : 0, Batch : 370, Loss : 0.05009382218122482\n",
      "Epoch : 0, Batch : 371, Loss : 0.042576588690280914\n",
      "Epoch : 0, Batch : 372, Loss : 0.0471724197268486\n",
      "Epoch : 0, Batch : 373, Loss : 0.046742748469114304\n",
      "Epoch : 0, Batch : 374, Loss : 0.043936483561992645\n",
      "Epoch : 0, Batch : 375, Loss : 0.050787389278411865\n",
      "Epoch : 0, Batch : 376, Loss : 0.05179977789521217\n",
      "Epoch : 0, Batch : 377, Loss : 0.04295361787080765\n",
      "Epoch : 0, Batch : 378, Loss : 0.050303880125284195\n",
      "Epoch : 0, Batch : 379, Loss : 0.050151873379945755\n",
      "Epoch : 0, Batch : 380, Loss : 0.04482356458902359\n",
      "Epoch : 0, Batch : 381, Loss : 0.048600733280181885\n",
      "Epoch : 0, Batch : 382, Loss : 0.04823462665081024\n",
      "Epoch : 0, Batch : 383, Loss : 0.05350201204419136\n",
      "Epoch : 0, Batch : 384, Loss : 0.05620014667510986\n",
      "Epoch : 0, Batch : 385, Loss : 0.045689359307289124\n",
      "Epoch : 0, Batch : 386, Loss : 0.050021927803754807\n",
      "Epoch : 0, Batch : 387, Loss : 0.04173637554049492\n",
      "Epoch : 0, Batch : 388, Loss : 0.0493944026529789\n",
      "Epoch : 0, Batch : 389, Loss : 0.05032357946038246\n",
      "Epoch : 0, Batch : 390, Loss : 0.045661360025405884\n",
      "Epoch : 0, Batch : 391, Loss : 0.045269839465618134\n",
      "Epoch : 0, Batch : 392, Loss : 0.047834791243076324\n",
      "Epoch : 0, Batch : 393, Loss : 0.044873982667922974\n",
      "Epoch : 0, Batch : 394, Loss : 0.041691854596138\n",
      "Epoch : 0, Batch : 395, Loss : 0.05162818729877472\n",
      "Epoch : 0, Batch : 396, Loss : 0.050713472068309784\n",
      "Epoch : 0, Batch : 397, Loss : 0.04937921464443207\n",
      "Epoch : 0, Batch : 398, Loss : 0.05568304657936096\n",
      "Epoch : 0, Batch : 399, Loss : 0.05674341320991516\n",
      "Epoch : 0, Batch : 400, Loss : 0.047326602041721344\n",
      "Epoch : 0, Batch : 401, Loss : 0.0575823038816452\n",
      "Epoch : 0, Batch : 402, Loss : 0.04502328485250473\n",
      "Epoch : 0, Batch : 403, Loss : 0.055022016167640686\n",
      "Epoch : 0, Batch : 404, Loss : 0.05267772078514099\n",
      "Epoch : 0, Batch : 405, Loss : 0.050586119294166565\n",
      "Epoch : 0, Batch : 406, Loss : 0.054599739611148834\n",
      "Epoch : 0, Batch : 407, Loss : 0.05037293583154678\n",
      "Epoch : 0, Batch : 408, Loss : 0.05528899282217026\n",
      "Epoch : 0, Batch : 409, Loss : 0.049490418285131454\n",
      "Epoch : 0, Batch : 410, Loss : 0.048581212759017944\n",
      "Epoch : 0, Batch : 411, Loss : 0.04193089157342911\n",
      "Epoch : 0, Batch : 412, Loss : 0.04919016733765602\n",
      "Epoch : 0, Batch : 413, Loss : 0.048349522054195404\n",
      "Epoch : 0, Batch : 414, Loss : 0.042802371084690094\n",
      "Epoch : 0, Batch : 415, Loss : 0.0485018789768219\n",
      "Epoch : 0, Batch : 416, Loss : 0.044113725423812866\n",
      "Epoch : 0, Batch : 417, Loss : 0.05438520386815071\n",
      "Epoch : 0, Batch : 418, Loss : 0.04396285489201546\n",
      "Epoch : 0, Batch : 419, Loss : 0.04451623558998108\n",
      "Epoch : 0, Batch : 420, Loss : 0.04110465943813324\n",
      "Epoch : 0, Batch : 421, Loss : 0.04704703763127327\n",
      "Epoch : 0, Batch : 422, Loss : 0.05026631057262421\n",
      "Epoch : 0, Batch : 423, Loss : 0.04672471433877945\n",
      "Epoch : 0, Batch : 424, Loss : 0.03996711224317551\n",
      "Epoch : 0, Batch : 425, Loss : 0.051831379532814026\n",
      "Epoch : 0, Batch : 426, Loss : 0.04880424961447716\n",
      "Epoch : 0, Batch : 427, Loss : 0.046789757907390594\n",
      "Epoch : 0, Batch : 428, Loss : 0.05062171444296837\n",
      "Epoch : 0, Batch : 429, Loss : 0.054332513362169266\n",
      "Epoch : 0, Batch : 430, Loss : 0.054284609854221344\n",
      "Epoch : 0, Batch : 431, Loss : 0.05025104433298111\n",
      "Epoch : 0, Batch : 432, Loss : 0.0465322881937027\n",
      "Epoch : 0, Batch : 433, Loss : 0.05772805213928223\n",
      "Epoch : 0, Batch : 434, Loss : 0.05387948080897331\n",
      "Epoch : 0, Batch : 435, Loss : 0.048986293375492096\n",
      "Epoch : 0, Batch : 436, Loss : 0.05704338103532791\n",
      "Epoch : 0, Batch : 437, Loss : 0.05394560843706131\n",
      "Epoch : 0, Batch : 438, Loss : 0.050679586827754974\n",
      "Epoch : 0, Batch : 439, Loss : 0.06104414165019989\n",
      "Epoch : 0, Batch : 440, Loss : 0.0590808168053627\n",
      "Epoch : 0, Batch : 441, Loss : 0.0545145720243454\n",
      "Epoch : 0, Batch : 442, Loss : 0.0502685084939003\n",
      "Epoch : 0, Batch : 443, Loss : 0.04640378803014755\n",
      "Epoch : 0, Batch : 444, Loss : 0.06098596751689911\n",
      "Epoch : 0, Batch : 445, Loss : 0.06447823345661163\n",
      "Epoch : 0, Batch : 446, Loss : 0.04898269101977348\n",
      "Epoch : 0, Batch : 447, Loss : 0.04998564347624779\n",
      "Epoch : 0, Batch : 448, Loss : 0.04640334099531174\n",
      "Epoch : 0, Batch : 449, Loss : 0.0512394905090332\n",
      "Epoch : 0, Batch : 450, Loss : 0.056151002645492554\n",
      "Epoch : 0, Batch : 451, Loss : 0.045228250324726105\n",
      "Epoch : 0, Batch : 452, Loss : 0.0493517704308033\n",
      "Epoch : 0, Batch : 453, Loss : 0.04622761905193329\n",
      "Epoch : 0, Batch : 454, Loss : 0.059892602264881134\n",
      "Epoch : 0, Batch : 455, Loss : 0.056838877499103546\n",
      "Epoch : 0, Batch : 456, Loss : 0.05191277340054512\n",
      "Epoch : 0, Batch : 457, Loss : 0.05187729001045227\n",
      "Epoch : 0, Batch : 458, Loss : 0.05658940225839615\n",
      "Epoch : 0, Batch : 459, Loss : 0.04129849374294281\n",
      "Epoch : 0, Batch : 460, Loss : 0.05646851658821106\n",
      "Epoch : 0, Batch : 461, Loss : 0.045764029026031494\n",
      "Epoch : 0, Batch : 462, Loss : 0.049081988632678986\n",
      "Epoch : 0, Batch : 463, Loss : 0.0406082347035408\n",
      "Epoch : 0, Batch : 464, Loss : 0.05329890549182892\n",
      "Epoch : 0, Batch : 465, Loss : 0.054146066308021545\n",
      "Epoch : 0, Batch : 466, Loss : 0.05470225214958191\n",
      "Epoch : 0, Batch : 467, Loss : 0.05384968966245651\n",
      "Epoch : 0, Batch : 468, Loss : 0.051702067255973816\n",
      "Epoch : 0, Batch : 469, Loss : 0.05284641683101654\n",
      "Epoch : 0, Batch : 470, Loss : 0.049798209220170975\n",
      "Epoch : 0, Batch : 471, Loss : 0.04723723232746124\n",
      "Epoch : 0, Batch : 472, Loss : 0.050429053604602814\n",
      "Epoch : 0, Batch : 473, Loss : 0.04786432534456253\n",
      "Epoch : 0, Batch : 474, Loss : 0.05107307434082031\n",
      "Epoch : 0, Batch : 475, Loss : 0.05585453659296036\n",
      "Epoch : 0, Batch : 476, Loss : 0.056929390877485275\n",
      "Epoch : 0, Batch : 477, Loss : 0.05791956186294556\n",
      "Epoch : 0, Batch : 478, Loss : 0.05590429529547691\n",
      "Epoch : 0, Batch : 479, Loss : 0.047537364065647125\n",
      "Epoch : 0, Batch : 480, Loss : 0.045008812099695206\n",
      "Epoch : 0, Batch : 481, Loss : 0.04325826093554497\n",
      "Epoch : 0, Batch : 482, Loss : 0.05327070504426956\n",
      "Epoch : 0, Batch : 483, Loss : 0.04535064101219177\n",
      "Epoch : 0, Batch : 484, Loss : 0.05629432201385498\n",
      "Epoch : 0, Batch : 485, Loss : 0.046966150403022766\n",
      "Epoch : 0, Batch : 486, Loss : 0.06290310621261597\n",
      "Epoch : 0, Batch : 487, Loss : 0.05402001738548279\n",
      "Epoch : 0, Batch : 488, Loss : 0.05114870145916939\n",
      "Epoch : 0, Batch : 489, Loss : 0.04249127209186554\n",
      "Epoch : 0, Batch : 490, Loss : 0.05195276439189911\n",
      "Epoch : 0, Batch : 491, Loss : 0.05412088334560394\n",
      "Epoch : 0, Batch : 492, Loss : 0.043968379497528076\n",
      "Epoch : 0, Batch : 493, Loss : 0.047896645963191986\n",
      "Epoch : 0, Batch : 494, Loss : 0.05333036929368973\n",
      "Epoch : 0, Batch : 495, Loss : 0.0497773140668869\n",
      "Epoch : 0, Batch : 496, Loss : 0.046857915818691254\n",
      "Epoch : 0, Batch : 497, Loss : 0.045566026121377945\n",
      "Epoch : 0, Batch : 498, Loss : 0.05369514599442482\n",
      "Epoch : 0, Batch : 499, Loss : 0.05602169781923294\n",
      "Epoch : 0, Batch : 500, Loss : 0.059379301965236664\n",
      "Epoch : 0, Batch : 501, Loss : 0.0395236611366272\n",
      "Epoch : 0, Batch : 502, Loss : 0.04918164759874344\n",
      "Epoch : 0, Batch : 503, Loss : 0.046357810497283936\n",
      "Epoch : 0, Batch : 504, Loss : 0.062330830842256546\n",
      "Epoch : 0, Batch : 505, Loss : 0.059366777539253235\n",
      "Epoch : 0, Batch : 506, Loss : 0.04874078184366226\n",
      "Epoch : 0, Batch : 507, Loss : 0.051508910953998566\n",
      "Epoch : 0, Batch : 508, Loss : 0.05407531559467316\n",
      "Epoch : 0, Batch : 509, Loss : 0.04765442758798599\n",
      "Epoch : 0, Batch : 510, Loss : 0.0487578883767128\n",
      "Epoch : 0, Batch : 511, Loss : 0.0633152648806572\n",
      "Epoch : 0, Batch : 512, Loss : 0.040719255805015564\n",
      "Epoch : 0, Batch : 513, Loss : 0.03957711160182953\n",
      "Epoch : 0, Batch : 514, Loss : 0.05038297921419144\n",
      "Epoch : 0, Batch : 515, Loss : 0.05979548767209053\n",
      "Epoch : 0, Batch : 516, Loss : 0.05286320671439171\n",
      "Epoch : 0, Batch : 517, Loss : 0.04653945565223694\n",
      "Epoch : 0, Batch : 518, Loss : 0.05051036551594734\n",
      "Epoch : 0, Batch : 519, Loss : 0.056202150881290436\n",
      "Epoch : 0, Batch : 520, Loss : 0.04260629415512085\n",
      "Epoch : 0, Batch : 521, Loss : 0.0419052317738533\n",
      "Epoch : 0, Batch : 522, Loss : 0.04770124703645706\n",
      "Epoch : 0, Batch : 523, Loss : 0.047060150653123856\n",
      "Epoch : 0, Batch : 524, Loss : 0.062017492949962616\n",
      "Epoch : 0, Batch : 525, Loss : 0.04997166991233826\n",
      "Epoch : 0, Batch : 526, Loss : 0.06111995130777359\n",
      "Epoch : 0, Batch : 527, Loss : 0.05698516219854355\n",
      "Epoch : 0, Batch : 528, Loss : 0.054024599492549896\n",
      "Epoch : 0, Batch : 529, Loss : 0.05225791037082672\n",
      "Epoch : 0, Batch : 530, Loss : 0.046302881091833115\n",
      "Epoch : 0, Batch : 531, Loss : 0.047220729291439056\n",
      "Epoch : 0, Batch : 532, Loss : 0.05369138717651367\n",
      "Epoch : 0, Batch : 533, Loss : 0.05043382570147514\n",
      "Epoch : 0, Batch : 534, Loss : 0.05121372640132904\n",
      "Epoch : 0, Batch : 535, Loss : 0.054440341889858246\n",
      "Epoch : 0, Batch : 536, Loss : 0.06023471802473068\n",
      "Epoch : 0, Batch : 537, Loss : 0.0499480739235878\n",
      "Epoch : 0, Batch : 538, Loss : 0.04992949217557907\n",
      "Epoch : 0, Batch : 539, Loss : 0.0475652813911438\n",
      "Epoch : 0, Batch : 540, Loss : 0.046971481293439865\n",
      "Epoch : 0, Batch : 541, Loss : 0.05023268237709999\n",
      "Epoch : 0, Batch : 542, Loss : 0.05044862627983093\n",
      "Epoch : 0, Batch : 543, Loss : 0.04725193977355957\n",
      "Epoch : 0, Batch : 544, Loss : 0.05398876592516899\n",
      "Epoch : 0, Batch : 545, Loss : 0.05457230284810066\n",
      "Epoch : 0, Batch : 546, Loss : 0.047204457223415375\n",
      "Epoch : 0, Batch : 547, Loss : 0.050992462784051895\n",
      "Epoch : 0, Batch : 548, Loss : 0.055642273277044296\n",
      "Epoch : 0, Batch : 549, Loss : 0.054405562579631805\n",
      "Epoch : 0, Batch : 550, Loss : 0.04679807275533676\n",
      "Epoch : 0, Batch : 551, Loss : 0.046602822840213776\n",
      "Epoch : 0, Batch : 552, Loss : 0.052069053053855896\n",
      "Epoch : 0, Batch : 553, Loss : 0.04524092376232147\n",
      "Epoch : 0, Batch : 554, Loss : 0.05173497274518013\n",
      "Epoch : 0, Batch : 555, Loss : 0.0510670468211174\n",
      "Epoch : 0, Batch : 556, Loss : 0.05478603392839432\n",
      "Epoch : 0, Batch : 557, Loss : 0.05041179805994034\n",
      "Epoch : 0, Batch : 558, Loss : 0.04130515083670616\n",
      "Epoch : 0, Batch : 559, Loss : 0.04960688203573227\n",
      "Epoch : 0, Batch : 560, Loss : 0.05714759975671768\n",
      "Epoch : 0, Batch : 561, Loss : 0.04952425882220268\n",
      "Epoch : 0, Batch : 562, Loss : 0.04392541944980621\n",
      "Epoch : 0, Batch : 563, Loss : 0.057169415056705475\n",
      "Epoch : 0, Batch : 564, Loss : 0.046290189027786255\n",
      "Epoch : 0, Batch : 565, Loss : 0.0436050146818161\n",
      "Epoch : 0, Batch : 566, Loss : 0.04990018904209137\n",
      "Epoch : 0, Batch : 567, Loss : 0.05240245163440704\n",
      "Epoch : 0, Batch : 568, Loss : 0.04466230422258377\n",
      "Epoch : 0, Batch : 569, Loss : 0.0497468039393425\n",
      "Epoch : 0, Batch : 570, Loss : 0.04853934794664383\n",
      "Epoch : 0, Batch : 571, Loss : 0.05273270979523659\n",
      "Epoch : 0, Batch : 572, Loss : 0.050073474645614624\n",
      "Epoch : 0, Batch : 573, Loss : 0.050187960267066956\n",
      "Epoch : 0, Batch : 574, Loss : 0.058346524834632874\n",
      "Epoch : 0, Batch : 575, Loss : 0.05445749685168266\n",
      "Epoch : 0, Batch : 576, Loss : 0.05086804926395416\n",
      "Epoch : 0, Batch : 577, Loss : 0.043556444346904755\n",
      "Epoch : 0, Batch : 578, Loss : 0.041009895503520966\n",
      "Epoch : 0, Batch : 579, Loss : 0.0567336231470108\n",
      "Epoch : 0, Batch : 580, Loss : 0.04980229586362839\n",
      "Epoch : 0, Batch : 581, Loss : 0.04106716066598892\n",
      "Epoch : 0, Batch : 582, Loss : 0.04761890321969986\n",
      "Epoch : 0, Batch : 583, Loss : 0.04899076372385025\n",
      "Epoch : 0, Batch : 584, Loss : 0.058699317276477814\n",
      "Epoch : 0, Batch : 585, Loss : 0.04915718361735344\n",
      "Epoch : 0, Batch : 586, Loss : 0.049804262816905975\n",
      "Epoch : 0, Batch : 587, Loss : 0.04165925458073616\n",
      "Epoch : 0, Batch : 588, Loss : 0.05101615935564041\n",
      "Epoch : 0, Batch : 589, Loss : 0.04712333530187607\n",
      "Epoch : 0, Batch : 590, Loss : 0.055213525891304016\n",
      "Epoch : 0, Batch : 591, Loss : 0.055079907178878784\n",
      "Epoch : 0, Batch : 592, Loss : 0.03850475698709488\n",
      "Epoch : 0, Batch : 593, Loss : 0.04526133090257645\n",
      "Epoch : 0, Batch : 594, Loss : 0.05618999898433685\n",
      "Epoch : 0, Batch : 595, Loss : 0.0464850515127182\n",
      "Epoch : 0, Batch : 596, Loss : 0.05187917500734329\n",
      "Epoch : 0, Batch : 597, Loss : 0.053477585315704346\n",
      "Epoch : 0, Batch : 598, Loss : 0.046969927847385406\n",
      "Epoch : 0, Batch : 599, Loss : 0.05529908835887909\n",
      "Epoch : 0, Batch : 600, Loss : 0.05738579481840134\n",
      "Epoch : 0, Batch : 601, Loss : 0.053699903190135956\n",
      "Epoch : 0, Batch : 602, Loss : 0.051528338342905045\n",
      "Epoch : 0, Batch : 603, Loss : 0.04399321228265762\n",
      "Epoch : 0, Batch : 604, Loss : 0.04806872457265854\n",
      "Epoch : 0, Batch : 605, Loss : 0.052939072251319885\n",
      "Epoch : 0, Batch : 606, Loss : 0.05332697182893753\n",
      "Epoch : 0, Batch : 607, Loss : 0.051079489290714264\n",
      "Epoch : 0, Batch : 608, Loss : 0.04870832711458206\n",
      "Epoch : 0, Batch : 609, Loss : 0.04522094875574112\n",
      "Epoch : 0, Batch : 610, Loss : 0.058765217661857605\n",
      "Epoch : 0, Batch : 611, Loss : 0.054354168474674225\n",
      "Epoch : 0, Batch : 612, Loss : 0.04241339489817619\n",
      "Epoch : 0, Batch : 613, Loss : 0.05339537560939789\n",
      "Epoch : 0, Batch : 614, Loss : 0.05304419621825218\n",
      "Epoch : 0, Batch : 615, Loss : 0.05604660138487816\n",
      "Epoch : 0, Batch : 616, Loss : 0.04410472512245178\n",
      "Epoch : 0, Batch : 617, Loss : 0.049121707677841187\n",
      "Epoch : 0, Batch : 618, Loss : 0.06554289907217026\n",
      "Epoch : 0, Batch : 619, Loss : 0.043681465089321136\n",
      "Epoch : 0, Batch : 620, Loss : 0.049025408923625946\n",
      "Epoch : 0, Batch : 621, Loss : 0.04124106839299202\n",
      "Epoch : 0, Batch : 622, Loss : 0.052099794149398804\n",
      "Epoch : 0, Batch : 623, Loss : 0.049353063106536865\n",
      "Epoch : 0, Batch : 624, Loss : 0.05152670294046402\n",
      "Epoch : 0, Batch : 625, Loss : 0.0624084398150444\n",
      "Epoch : 0, Batch : 626, Loss : 0.05663827806711197\n",
      "Epoch : 0, Batch : 627, Loss : 0.04979166388511658\n",
      "Epoch : 0, Batch : 628, Loss : 0.05211091786623001\n",
      "Epoch : 0, Batch : 629, Loss : 0.052558280527591705\n",
      "Epoch : 0, Batch : 630, Loss : 0.0509919710457325\n",
      "Epoch : 0, Batch : 631, Loss : 0.051407963037490845\n",
      "Epoch : 0, Batch : 632, Loss : 0.04401390999555588\n",
      "Epoch : 0, Batch : 633, Loss : 0.05063466727733612\n",
      "Epoch : 0, Batch : 634, Loss : 0.053299471735954285\n",
      "Epoch : 0, Batch : 635, Loss : 0.05331467464566231\n",
      "Epoch : 0, Batch : 636, Loss : 0.04828571528196335\n",
      "Epoch : 0, Batch : 637, Loss : 0.045902542769908905\n",
      "Epoch : 0, Batch : 638, Loss : 0.0458395853638649\n",
      "Epoch : 0, Batch : 639, Loss : 0.04243992269039154\n",
      "Epoch : 0, Batch : 640, Loss : 0.04943834990262985\n",
      "Epoch : 0, Batch : 641, Loss : 0.058632269501686096\n",
      "Epoch : 0, Batch : 642, Loss : 0.043708037585020065\n",
      "Epoch : 0, Batch : 643, Loss : 0.04325948655605316\n",
      "Epoch : 0, Batch : 644, Loss : 0.05255313962697983\n",
      "Epoch : 0, Batch : 645, Loss : 0.05469353497028351\n",
      "Epoch : 0, Batch : 646, Loss : 0.06069335713982582\n",
      "Epoch : 0, Batch : 647, Loss : 0.057114265859127045\n",
      "Epoch : 0, Batch : 648, Loss : 0.05140096694231033\n",
      "Epoch : 0, Batch : 649, Loss : 0.052574291825294495\n",
      "Epoch : 0, Batch : 650, Loss : 0.049746766686439514\n",
      "Epoch : 0, Batch : 651, Loss : 0.049867868423461914\n",
      "Epoch : 0, Batch : 652, Loss : 0.0441795252263546\n",
      "Epoch : 0, Batch : 653, Loss : 0.055218473076820374\n",
      "Epoch : 0, Batch : 654, Loss : 0.05405564606189728\n",
      "Epoch : 0, Batch : 655, Loss : 0.05250335857272148\n",
      "Epoch : 0, Batch : 656, Loss : 0.04632771760225296\n",
      "Epoch : 0, Batch : 657, Loss : 0.049987323582172394\n",
      "Epoch : 0, Batch : 658, Loss : 0.05592167377471924\n",
      "Epoch : 0, Batch : 659, Loss : 0.05731066316366196\n",
      "Epoch : 0, Batch : 660, Loss : 0.04945400357246399\n",
      "Epoch : 0, Batch : 661, Loss : 0.056399837136268616\n",
      "Epoch : 0, Batch : 662, Loss : 0.05503900349140167\n",
      "Epoch : 0, Batch : 663, Loss : 0.0491662323474884\n",
      "Epoch : 0, Batch : 664, Loss : 0.046453073620796204\n",
      "Epoch : 0, Batch : 665, Loss : 0.052134960889816284\n",
      "Epoch : 0, Batch : 666, Loss : 0.040566958487033844\n",
      "Epoch : 0, Batch : 667, Loss : 0.05446340888738632\n",
      "Epoch : 0, Batch : 668, Loss : 0.046762362122535706\n",
      "Epoch : 0, Batch : 669, Loss : 0.05520692467689514\n",
      "Epoch : 0, Batch : 670, Loss : 0.05259532481431961\n",
      "Epoch : 0, Batch : 671, Loss : 0.05175739526748657\n",
      "Epoch : 0, Batch : 672, Loss : 0.05487769469618797\n",
      "Epoch : 0, Batch : 673, Loss : 0.05167052149772644\n",
      "Epoch : 0, Batch : 674, Loss : 0.04888378083705902\n",
      "Epoch : 0, Batch : 675, Loss : 0.050590381026268005\n",
      "Epoch : 0, Batch : 676, Loss : 0.04174897074699402\n",
      "Epoch : 0, Batch : 677, Loss : 0.04661601781845093\n",
      "Epoch : 0, Batch : 678, Loss : 0.046828947961330414\n",
      "Epoch : 0, Batch : 679, Loss : 0.05389021709561348\n",
      "Epoch : 0, Batch : 680, Loss : 0.04921690374612808\n",
      "Epoch : 0, Batch : 681, Loss : 0.05696028843522072\n",
      "Epoch : 0, Batch : 682, Loss : 0.049035318195819855\n",
      "Epoch : 0, Batch : 683, Loss : 0.04990677163004875\n",
      "Epoch : 0, Batch : 684, Loss : 0.056938536465168\n",
      "Epoch : 0, Batch : 685, Loss : 0.04932356998324394\n",
      "Epoch : 0, Batch : 686, Loss : 0.05579506233334541\n",
      "Epoch : 0, Batch : 687, Loss : 0.048592694103717804\n",
      "Epoch : 0, Batch : 688, Loss : 0.04564078152179718\n",
      "Epoch : 0, Batch : 689, Loss : 0.05294285714626312\n",
      "Epoch : 0, Batch : 690, Loss : 0.061293575912714005\n",
      "Epoch : 0, Batch : 691, Loss : 0.04176551103591919\n",
      "Epoch : 0, Batch : 692, Loss : 0.05047224462032318\n",
      "Epoch : 0, Batch : 693, Loss : 0.043899357318878174\n",
      "Epoch : 0, Batch : 694, Loss : 0.05585923790931702\n",
      "Epoch : 0, Batch : 695, Loss : 0.051505789160728455\n",
      "Epoch : 0, Batch : 696, Loss : 0.04963230341672897\n",
      "Epoch : 0, Batch : 697, Loss : 0.04749146103858948\n",
      "Epoch : 0, Batch : 698, Loss : 0.05699143558740616\n",
      "Epoch : 0, Batch : 699, Loss : 0.05019132047891617\n",
      "Epoch : 0, Batch : 700, Loss : 0.047821030020713806\n",
      "Epoch : 0, Batch : 701, Loss : 0.05243963003158569\n",
      "Epoch : 0, Batch : 702, Loss : 0.04674636200070381\n",
      "Epoch : 0, Batch : 703, Loss : 0.054671257734298706\n",
      "Epoch : 0, Batch : 704, Loss : 0.052467942237854004\n",
      "Epoch : 0, Batch : 705, Loss : 0.047654952853918076\n",
      "Epoch : 0, Batch : 706, Loss : 0.055548183619976044\n",
      "Epoch : 0, Batch : 707, Loss : 0.049647144973278046\n",
      "Epoch : 0, Batch : 708, Loss : 0.05028598755598068\n",
      "Epoch : 0, Batch : 709, Loss : 0.046753887087106705\n",
      "Epoch : 0, Batch : 710, Loss : 0.05165178328752518\n",
      "Epoch : 0, Batch : 711, Loss : 0.04717281460762024\n",
      "Epoch : 0, Batch : 712, Loss : 0.05956795811653137\n",
      "Epoch : 0, Batch : 713, Loss : 0.046055372804403305\n",
      "Epoch : 0, Batch : 714, Loss : 0.054668135941028595\n",
      "Epoch : 0, Batch : 715, Loss : 0.054530322551727295\n",
      "Epoch : 0, Batch : 716, Loss : 0.04804425686597824\n",
      "Epoch : 0, Batch : 717, Loss : 0.04807788506150246\n",
      "Epoch : 0, Batch : 718, Loss : 0.05452921986579895\n",
      "Epoch : 0, Batch : 719, Loss : 0.04485836252570152\n",
      "Epoch : 0, Batch : 720, Loss : 0.05395500361919403\n",
      "Epoch : 0, Batch : 721, Loss : 0.04883231967687607\n",
      "Epoch : 0, Batch : 722, Loss : 0.05288271605968475\n",
      "Epoch : 0, Batch : 723, Loss : 0.04529663920402527\n",
      "Epoch : 0, Batch : 724, Loss : 0.04891211539506912\n",
      "Epoch : 0, Batch : 725, Loss : 0.05352730304002762\n",
      "Epoch : 0, Batch : 726, Loss : 0.04875706881284714\n",
      "Epoch : 0, Batch : 727, Loss : 0.0523066446185112\n",
      "Epoch : 0, Batch : 728, Loss : 0.04830053076148033\n",
      "Epoch : 0, Batch : 729, Loss : 0.04923485219478607\n",
      "Epoch : 0, Batch : 730, Loss : 0.051418352872133255\n",
      "Epoch : 0, Batch : 731, Loss : 0.046709172427654266\n",
      "Epoch : 0, Batch : 732, Loss : 0.052817754447460175\n",
      "Epoch : 0, Batch : 733, Loss : 0.04962349683046341\n",
      "Epoch : 0, Batch : 734, Loss : 0.04831952601671219\n",
      "Epoch : 0, Batch : 735, Loss : 0.0505015030503273\n",
      "Epoch : 0, Batch : 736, Loss : 0.04482883960008621\n",
      "Epoch : 0, Batch : 737, Loss : 0.052479423582553864\n",
      "Epoch : 0, Batch : 738, Loss : 0.055754728615283966\n",
      "Epoch : 0, Batch : 739, Loss : 0.049822475761175156\n",
      "Epoch : 0, Batch : 740, Loss : 0.05353488400578499\n",
      "Epoch : 0, Batch : 741, Loss : 0.052625324577093124\n",
      "Epoch : 0, Batch : 742, Loss : 0.04921143129467964\n",
      "Epoch : 0, Batch : 743, Loss : 0.054823219776153564\n",
      "Epoch : 0, Batch : 744, Loss : 0.05187077820301056\n",
      "Epoch : 0, Batch : 745, Loss : 0.05259835720062256\n",
      "Epoch : 0, Batch : 746, Loss : 0.04954660311341286\n",
      "Epoch : 0, Batch : 747, Loss : 0.05323846638202667\n",
      "Epoch : 0, Batch : 748, Loss : 0.053863413631916046\n",
      "Epoch : 0, Batch : 749, Loss : 0.054537564516067505\n",
      "Epoch : 0, Batch : 750, Loss : 0.049222126603126526\n",
      "Epoch : 0, Batch : 751, Loss : 0.05002649500966072\n",
      "Epoch : 0, Batch : 752, Loss : 0.054849401116371155\n",
      "Epoch : 0, Batch : 753, Loss : 0.05673648416996002\n",
      "Epoch : 0, Batch : 754, Loss : 0.04048234224319458\n",
      "Epoch : 0, Batch : 755, Loss : 0.05521068722009659\n",
      "Epoch : 0, Batch : 756, Loss : 0.05541328340768814\n",
      "Epoch : 0, Batch : 757, Loss : 0.04788750782608986\n",
      "Epoch : 0, Batch : 758, Loss : 0.05234489589929581\n",
      "Epoch : 0, Batch : 759, Loss : 0.049287647008895874\n",
      "Epoch : 0, Batch : 760, Loss : 0.04749432951211929\n",
      "Epoch : 0, Batch : 761, Loss : 0.06004389375448227\n",
      "Epoch : 0, Batch : 762, Loss : 0.04882798343896866\n",
      "Epoch : 0, Batch : 763, Loss : 0.04923352226614952\n",
      "Epoch : 0, Batch : 764, Loss : 0.058413099497556686\n",
      "Epoch : 0, Batch : 765, Loss : 0.05197793245315552\n",
      "Epoch : 0, Batch : 766, Loss : 0.0459647998213768\n",
      "Epoch : 0, Batch : 767, Loss : 0.050134800374507904\n",
      "Epoch : 0, Batch : 768, Loss : 0.05393712967634201\n",
      "Epoch : 0, Batch : 769, Loss : 0.0491124764084816\n",
      "Epoch : 0, Batch : 770, Loss : 0.045430514961481094\n",
      "Epoch : 0, Batch : 771, Loss : 0.056394752115011215\n",
      "Epoch : 0, Batch : 772, Loss : 0.05109293386340141\n",
      "Epoch : 0, Batch : 773, Loss : 0.04546595364809036\n",
      "Epoch : 0, Batch : 774, Loss : 0.04952557757496834\n",
      "Epoch : 0, Batch : 775, Loss : 0.04577776789665222\n",
      "Epoch : 0, Batch : 776, Loss : 0.051255181431770325\n",
      "Epoch : 0, Batch : 777, Loss : 0.05289618670940399\n",
      "Epoch : 0, Batch : 778, Loss : 0.044217824935913086\n",
      "Epoch : 0, Batch : 779, Loss : 0.05494910106062889\n",
      "Epoch : 0, Batch : 780, Loss : 0.05389326065778732\n",
      "Epoch : 0, Batch : 781, Loss : 0.046906836330890656\n",
      "Epoch : 0, Batch : 782, Loss : 0.048247843980789185\n",
      "Epoch : 0, Batch : 783, Loss : 0.05548641458153725\n",
      "Epoch : 0, Batch : 784, Loss : 0.05194444954395294\n",
      "Epoch : 0, Batch : 785, Loss : 0.04892530292272568\n",
      "Epoch : 0, Batch : 786, Loss : 0.04920865595340729\n",
      "Epoch : 0, Batch : 787, Loss : 0.04408480226993561\n",
      "Epoch : 0, Batch : 788, Loss : 0.048519231379032135\n",
      "Epoch : 0, Batch : 789, Loss : 0.057656995952129364\n",
      "Epoch : 0, Batch : 790, Loss : 0.05169764533638954\n",
      "Epoch : 0, Batch : 791, Loss : 0.050477348268032074\n",
      "Epoch : 0, Batch : 792, Loss : 0.049791041761636734\n",
      "Epoch : 0, Batch : 793, Loss : 0.05225647985935211\n",
      "Epoch : 0, Batch : 794, Loss : 0.04729870706796646\n",
      "Epoch : 0, Batch : 795, Loss : 0.05822645500302315\n",
      "Epoch : 0, Batch : 796, Loss : 0.05368626490235329\n",
      "Epoch : 0, Batch : 797, Loss : 0.05222059413790703\n",
      "Epoch : 0, Batch : 798, Loss : 0.05195291340351105\n",
      "Epoch : 0, Batch : 799, Loss : 0.05492597445845604\n",
      "Epoch : 0, Batch : 800, Loss : 0.05680101737380028\n",
      "Epoch : 0, Batch : 801, Loss : 0.04890719801187515\n",
      "Epoch : 0, Batch : 802, Loss : 0.04734930023550987\n",
      "Epoch : 0, Batch : 803, Loss : 0.048600319772958755\n",
      "Epoch : 0, Batch : 804, Loss : 0.052036479115486145\n",
      "Epoch : 0, Batch : 805, Loss : 0.05670531466603279\n",
      "Epoch : 0, Batch : 806, Loss : 0.04999857395887375\n",
      "Epoch : 0, Batch : 807, Loss : 0.05680067837238312\n",
      "Epoch : 0, Batch : 808, Loss : 0.06085433065891266\n",
      "Epoch : 0, Batch : 809, Loss : 0.049133218824863434\n",
      "Epoch : 0, Batch : 810, Loss : 0.05217713490128517\n",
      "Epoch : 0, Batch : 811, Loss : 0.03941711038351059\n",
      "Epoch : 0, Batch : 812, Loss : 0.04806230217218399\n",
      "Epoch : 0, Batch : 813, Loss : 0.05093277618288994\n",
      "Epoch : 0, Batch : 814, Loss : 0.048865705728530884\n",
      "Epoch : 0, Batch : 815, Loss : 0.05011075735092163\n",
      "Epoch : 0, Batch : 816, Loss : 0.04496791586279869\n",
      "Epoch : 0, Batch : 817, Loss : 0.0420125313103199\n",
      "Epoch : 0, Batch : 818, Loss : 0.04895811527967453\n",
      "Epoch : 0, Batch : 819, Loss : 0.04128832370042801\n",
      "Epoch : 0, Batch : 820, Loss : 0.05026353895664215\n",
      "Epoch : 0, Batch : 821, Loss : 0.054784245789051056\n",
      "Epoch : 0, Batch : 822, Loss : 0.05095432698726654\n",
      "Epoch : 0, Batch : 823, Loss : 0.04987981542944908\n",
      "Epoch : 0, Batch : 824, Loss : 0.0548093244433403\n",
      "Epoch : 0, Batch : 825, Loss : 0.04652343690395355\n",
      "Epoch : 0, Batch : 826, Loss : 0.04494853317737579\n",
      "Epoch : 0, Batch : 827, Loss : 0.0550859197974205\n",
      "Epoch : 0, Batch : 828, Loss : 0.05030810832977295\n",
      "Epoch : 0, Batch : 829, Loss : 0.051072195172309875\n",
      "Epoch : 0, Batch : 830, Loss : 0.05023452267050743\n",
      "Epoch : 0, Batch : 831, Loss : 0.04916085675358772\n",
      "Epoch : 0, Batch : 832, Loss : 0.045502059161663055\n",
      "Epoch : 0, Batch : 833, Loss : 0.050219275057315826\n",
      "Epoch : 0, Batch : 834, Loss : 0.05407238006591797\n",
      "Epoch : 0, Batch : 835, Loss : 0.04690779000520706\n",
      "Epoch : 0, Batch : 836, Loss : 0.053662218153476715\n",
      "Epoch : 0, Batch : 837, Loss : 0.04739852622151375\n",
      "Epoch : 0, Batch : 838, Loss : 0.06098365783691406\n",
      "Epoch : 0, Batch : 839, Loss : 0.05084041878581047\n",
      "Epoch : 0, Batch : 840, Loss : 0.05688938498497009\n",
      "Epoch : 0, Batch : 841, Loss : 0.05860652029514313\n",
      "Epoch : 0, Batch : 842, Loss : 0.04979066550731659\n",
      "Epoch : 0, Batch : 843, Loss : 0.0465109720826149\n",
      "Epoch : 0, Batch : 844, Loss : 0.0569353811442852\n",
      "Epoch : 0, Batch : 845, Loss : 0.054096996784210205\n",
      "Epoch : 0, Batch : 846, Loss : 0.04953417181968689\n",
      "Epoch : 0, Batch : 847, Loss : 0.04989643394947052\n",
      "Epoch : 0, Batch : 848, Loss : 0.053160425275564194\n",
      "Epoch : 0, Batch : 849, Loss : 0.05758465826511383\n",
      "Epoch : 0, Batch : 850, Loss : 0.04709186404943466\n",
      "Epoch : 0, Batch : 851, Loss : 0.05030035972595215\n",
      "Epoch : 0, Batch : 852, Loss : 0.055030375719070435\n",
      "Epoch : 0, Batch : 853, Loss : 0.04823439568281174\n",
      "Epoch : 0, Batch : 854, Loss : 0.057534173130989075\n",
      "Epoch : 0, Batch : 855, Loss : 0.059391506016254425\n",
      "Epoch : 0, Batch : 856, Loss : 0.04545755684375763\n",
      "Epoch : 0, Batch : 857, Loss : 0.0540790855884552\n",
      "Epoch : 0, Batch : 858, Loss : 0.05019787326455116\n",
      "Epoch : 0, Batch : 859, Loss : 0.04847254604101181\n",
      "Epoch : 0, Batch : 860, Loss : 0.05139278247952461\n",
      "Epoch : 0, Batch : 861, Loss : 0.05081292241811752\n",
      "Epoch : 0, Batch : 862, Loss : 0.04413684457540512\n",
      "Epoch : 0, Batch : 863, Loss : 0.047864750027656555\n",
      "Epoch : 0, Batch : 864, Loss : 0.051743246614933014\n",
      "Epoch : 0, Batch : 865, Loss : 0.046362996101379395\n",
      "Epoch : 0, Batch : 866, Loss : 0.05303020030260086\n",
      "Epoch : 0, Batch : 867, Loss : 0.04888699948787689\n",
      "Epoch : 0, Batch : 868, Loss : 0.05430122837424278\n",
      "Epoch : 0, Batch : 869, Loss : 0.05283086374402046\n",
      "Epoch : 0, Batch : 870, Loss : 0.041742078959941864\n",
      "Epoch : 0, Batch : 871, Loss : 0.05183945596218109\n",
      "Epoch : 0, Batch : 872, Loss : 0.051019445061683655\n",
      "Epoch : 0, Batch : 873, Loss : 0.04495195671916008\n",
      "Epoch : 0, Batch : 874, Loss : 0.044169217348098755\n",
      "Epoch : 0, Batch : 875, Loss : 0.04817666858434677\n",
      "Epoch : 0, Batch : 876, Loss : 0.04969558119773865\n",
      "Epoch : 0, Batch : 877, Loss : 0.04709674417972565\n",
      "Epoch : 0, Batch : 878, Loss : 0.04724927991628647\n",
      "Epoch : 0, Batch : 879, Loss : 0.04936482012271881\n",
      "Epoch : 0, Batch : 880, Loss : 0.05336034297943115\n",
      "Epoch : 0, Batch : 881, Loss : 0.054987408220767975\n",
      "Epoch : 0, Batch : 882, Loss : 0.047700557857751846\n",
      "Epoch : 0, Batch : 883, Loss : 0.054705288261175156\n",
      "Epoch : 0, Batch : 884, Loss : 0.054819412529468536\n",
      "Epoch : 0, Batch : 885, Loss : 0.05198211595416069\n",
      "Epoch : 0, Batch : 886, Loss : 0.0598362535238266\n",
      "Epoch : 0, Batch : 887, Loss : 0.04478474706411362\n",
      "Epoch : 0, Batch : 888, Loss : 0.048671141266822815\n",
      "Epoch : 0, Batch : 889, Loss : 0.052622731775045395\n",
      "Epoch : 0, Batch : 890, Loss : 0.05255984514951706\n",
      "Epoch : 0, Batch : 891, Loss : 0.04611291363835335\n",
      "Epoch : 0, Batch : 892, Loss : 0.05320350080728531\n",
      "Epoch : 0, Batch : 893, Loss : 0.048719704151153564\n",
      "Epoch : 0, Batch : 894, Loss : 0.047217100858688354\n",
      "Epoch : 0, Batch : 895, Loss : 0.057646624743938446\n",
      "Epoch : 0, Batch : 896, Loss : 0.04563484340906143\n",
      "Epoch : 0, Batch : 897, Loss : 0.05105617642402649\n",
      "Epoch : 0, Batch : 898, Loss : 0.04858465492725372\n",
      "Epoch : 0, Batch : 899, Loss : 0.05405065789818764\n",
      "Epoch : 0, Batch : 900, Loss : 0.05857814475893974\n",
      "Epoch : 0, Batch : 901, Loss : 0.04430179297924042\n",
      "Epoch : 0, Batch : 902, Loss : 0.04460158944129944\n",
      "Epoch : 0, Batch : 903, Loss : 0.043528370559215546\n",
      "Epoch : 0, Batch : 904, Loss : 0.049831464886665344\n",
      "Epoch : 0, Batch : 905, Loss : 0.05385362356901169\n",
      "Epoch : 0, Batch : 906, Loss : 0.05330255627632141\n",
      "Epoch : 0, Batch : 907, Loss : 0.04639844596385956\n",
      "Epoch : 0, Batch : 908, Loss : 0.04769860953092575\n",
      "Epoch : 0, Batch : 909, Loss : 0.0551045797765255\n",
      "Epoch : 0, Batch : 910, Loss : 0.04630986601114273\n",
      "Epoch : 0, Batch : 911, Loss : 0.05619494989514351\n",
      "Epoch : 0, Batch : 912, Loss : 0.05313211679458618\n",
      "Epoch : 0, Batch : 913, Loss : 0.04603606462478638\n",
      "Epoch : 0, Batch : 914, Loss : 0.05550137534737587\n",
      "Epoch : 0, Batch : 915, Loss : 0.05420282483100891\n",
      "Epoch : 0, Batch : 916, Loss : 0.0485273152589798\n",
      "Epoch : 0, Batch : 917, Loss : 0.05539809539914131\n",
      "Epoch : 0, Batch : 918, Loss : 0.05035371705889702\n",
      "Epoch : 0, Batch : 919, Loss : 0.04332181066274643\n",
      "Epoch : 0, Batch : 920, Loss : 0.05230121687054634\n",
      "Epoch : 0, Batch : 921, Loss : 0.05103270709514618\n",
      "Epoch : 0, Batch : 922, Loss : 0.0475594662129879\n",
      "Epoch : 0, Batch : 923, Loss : 0.05327124521136284\n",
      "Epoch : 0, Batch : 924, Loss : 0.050077151507139206\n",
      "Epoch : 0, Batch : 925, Loss : 0.04407073184847832\n",
      "Epoch : 0, Batch : 926, Loss : 0.04495477303862572\n",
      "Epoch : 0, Batch : 927, Loss : 0.05193182826042175\n",
      "Epoch : 0, Batch : 928, Loss : 0.04498477652668953\n",
      "Epoch : 0, Batch : 929, Loss : 0.04861415922641754\n",
      "Epoch : 0, Batch : 930, Loss : 0.05780741944909096\n",
      "Epoch : 0, Batch : 931, Loss : 0.061090532690286636\n",
      "Epoch : 0, Batch : 932, Loss : 0.05468902736902237\n",
      "Epoch : 0, Batch : 933, Loss : 0.0486937090754509\n",
      "Epoch : 0, Batch : 934, Loss : 0.0516526997089386\n",
      "Epoch : 0, Batch : 935, Loss : 0.0567803792655468\n",
      "Epoch : 0, Batch : 936, Loss : 0.05047019571065903\n",
      "Epoch : 0, Batch : 937, Loss : 0.04868786036968231\n",
      "Epoch : 0, Batch : 938, Loss : 0.04773596674203873\n",
      "Epoch : 0, Batch : 939, Loss : 0.048614032566547394\n",
      "Epoch : 0, Batch : 940, Loss : 0.06313464045524597\n",
      "Epoch : 0, Batch : 941, Loss : 0.05685470253229141\n",
      "Epoch : 0, Batch : 942, Loss : 0.04400935769081116\n",
      "Epoch : 0, Batch : 943, Loss : 0.04016174003481865\n",
      "Epoch : 0, Batch : 944, Loss : 0.04213012009859085\n",
      "Epoch : 0, Batch : 945, Loss : 0.041894324123859406\n",
      "Epoch : 0, Batch : 946, Loss : 0.048315804451704025\n",
      "Epoch : 0, Batch : 947, Loss : 0.052297115325927734\n",
      "Epoch : 0, Batch : 948, Loss : 0.04609782621264458\n",
      "Epoch : 0, Batch : 949, Loss : 0.04862646013498306\n",
      "Epoch : 0, Batch : 950, Loss : 0.05344245582818985\n",
      "Epoch : 0, Batch : 951, Loss : 0.04575512558221817\n",
      "Epoch : 0, Batch : 952, Loss : 0.05357136204838753\n",
      "Epoch : 0, Batch : 953, Loss : 0.04671555757522583\n",
      "Epoch : 0, Batch : 954, Loss : 0.04860055819153786\n",
      "Epoch : 0, Batch : 955, Loss : 0.049943916499614716\n",
      "Epoch : 0, Batch : 956, Loss : 0.051027148962020874\n",
      "Epoch : 0, Batch : 957, Loss : 0.048282440751791\n",
      "Epoch : 0, Batch : 958, Loss : 0.04414729028940201\n",
      "Epoch : 0, Batch : 959, Loss : 0.05057370662689209\n",
      "Epoch : 0, Batch : 960, Loss : 0.04774578660726547\n",
      "Epoch : 0, Batch : 961, Loss : 0.050788406282663345\n",
      "Epoch : 0, Batch : 962, Loss : 0.04708005487918854\n",
      "Epoch : 0, Batch : 963, Loss : 0.05059962719678879\n",
      "Epoch : 0, Batch : 964, Loss : 0.04435056447982788\n",
      "Epoch : 0, Batch : 965, Loss : 0.046823274344205856\n",
      "Epoch : 0, Batch : 966, Loss : 0.055813267827034\n",
      "Epoch : 0, Batch : 967, Loss : 0.05061449110507965\n",
      "Epoch : 0, Batch : 968, Loss : 0.04565509408712387\n",
      "Epoch : 0, Batch : 969, Loss : 0.04924945533275604\n",
      "Epoch : 0, Batch : 970, Loss : 0.045359328389167786\n",
      "Epoch : 0, Batch : 971, Loss : 0.048734329640865326\n",
      "Epoch : 0, Batch : 972, Loss : 0.05294033885002136\n",
      "Epoch : 0, Batch : 973, Loss : 0.051012974232435226\n",
      "Epoch : 0, Batch : 974, Loss : 0.049494050443172455\n",
      "Epoch : 0, Batch : 975, Loss : 0.049085721373558044\n",
      "Epoch : 0, Batch : 976, Loss : 0.05220288038253784\n",
      "Epoch : 0, Batch : 977, Loss : 0.05052630975842476\n",
      "Epoch : 0, Batch : 978, Loss : 0.045684121549129486\n",
      "Epoch : 0, Batch : 979, Loss : 0.046862050890922546\n",
      "Epoch : 0, Batch : 980, Loss : 0.03986630588769913\n",
      "Epoch : 0, Batch : 981, Loss : 0.055600427091121674\n",
      "Epoch : 0, Batch : 982, Loss : 0.057701170444488525\n",
      "Epoch : 0, Batch : 983, Loss : 0.05046035349369049\n",
      "Epoch : 0, Batch : 984, Loss : 0.054060909897089005\n",
      "Epoch : 0, Batch : 985, Loss : 0.044362980872392654\n",
      "Epoch : 0, Batch : 986, Loss : 0.04879189282655716\n",
      "Epoch : 0, Batch : 987, Loss : 0.047981537878513336\n",
      "Epoch : 0, Batch : 988, Loss : 0.046523161232471466\n",
      "Epoch : 0, Batch : 989, Loss : 0.04592083394527435\n",
      "Epoch : 0, Batch : 990, Loss : 0.049802251160144806\n",
      "Epoch : 0, Batch : 991, Loss : 0.060888711363077164\n",
      "Epoch : 0, Batch : 992, Loss : 0.049075208604335785\n",
      "Epoch : 0, Batch : 993, Loss : 0.04709787294268608\n",
      "Epoch : 0, Batch : 994, Loss : 0.051901016384363174\n",
      "Epoch : 0, Batch : 995, Loss : 0.04207388311624527\n",
      "Epoch : 0, Batch : 996, Loss : 0.04903678223490715\n",
      "Epoch : 0, Batch : 997, Loss : 0.049866870045661926\n",
      "Epoch : 0, Batch : 998, Loss : 0.05034070461988449\n",
      "Epoch : 0, Batch : 999, Loss : 0.05128879100084305\n",
      "Epoch : 0, Batch : 1000, Loss : 0.05204454064369202\n",
      "Epoch : 0, Batch : 1001, Loss : 0.051423102617263794\n",
      "Epoch : 0, Batch : 1002, Loss : 0.04778455197811127\n",
      "Epoch : 0, Batch : 1003, Loss : 0.0485081747174263\n",
      "Epoch : 0, Batch : 1004, Loss : 0.04855939745903015\n",
      "Epoch : 0, Batch : 1005, Loss : 0.05274408683180809\n",
      "Epoch : 0, Batch : 1006, Loss : 0.05375312641263008\n",
      "Epoch : 0, Batch : 1007, Loss : 0.0490834042429924\n",
      "Epoch : 0, Batch : 1008, Loss : 0.054024845361709595\n",
      "Epoch : 0, Batch : 1009, Loss : 0.042047373950481415\n",
      "Epoch : 0, Batch : 1010, Loss : 0.04745571315288544\n",
      "Epoch : 0, Batch : 1011, Loss : 0.045102309435606\n",
      "Epoch : 0, Batch : 1012, Loss : 0.052492544054985046\n",
      "Epoch : 0, Batch : 1013, Loss : 0.04905488342046738\n",
      "Epoch : 0, Batch : 1014, Loss : 0.05376793444156647\n",
      "Epoch : 0, Batch : 1015, Loss : 0.0529395267367363\n",
      "Epoch : 0, Batch : 1016, Loss : 0.05778336524963379\n",
      "Epoch : 0, Batch : 1017, Loss : 0.05374020338058472\n",
      "Epoch : 0, Batch : 1018, Loss : 0.052377376705408096\n",
      "Epoch : 0, Batch : 1019, Loss : 0.04804842174053192\n",
      "Epoch : 0, Batch : 1020, Loss : 0.04665178060531616\n",
      "Epoch : 0, Batch : 1021, Loss : 0.054350048303604126\n",
      "Epoch : 0, Batch : 1022, Loss : 0.056469205766916275\n",
      "Epoch : 0, Batch : 1023, Loss : 0.05634436011314392\n",
      "Epoch : 0, Batch : 1024, Loss : 0.054359372705221176\n",
      "Epoch : 0, Batch : 1025, Loss : 0.05097385495901108\n",
      "Epoch : 0, Batch : 1026, Loss : 0.043204162269830704\n",
      "Epoch : 0, Batch : 1027, Loss : 0.05078282952308655\n",
      "Epoch : 0, Batch : 1028, Loss : 0.04419802129268646\n",
      "Epoch : 0, Batch : 1029, Loss : 0.04980766773223877\n",
      "Epoch : 0, Batch : 1030, Loss : 0.057057544589042664\n",
      "Epoch : 0, Batch : 1031, Loss : 0.05187040567398071\n",
      "Epoch : 0, Batch : 1032, Loss : 0.04629313573241234\n",
      "Epoch : 0, Batch : 1033, Loss : 0.057946790009737015\n",
      "Epoch : 0, Batch : 1034, Loss : 0.0451834574341774\n",
      "Epoch : 0, Batch : 1035, Loss : 0.05687393993139267\n",
      "Epoch : 0, Batch : 1036, Loss : 0.049315571784973145\n",
      "Epoch : 0, Batch : 1037, Loss : 0.051510557532310486\n",
      "Epoch : 0, Batch : 1038, Loss : 0.05246376991271973\n",
      "Epoch : 0, Batch : 1039, Loss : 0.05225619301199913\n",
      "Epoch : 0, Batch : 1040, Loss : 0.05173921212553978\n",
      "Epoch : 0, Batch : 1041, Loss : 0.04925457760691643\n",
      "Epoch : 0, Batch : 1042, Loss : 0.05487837269902229\n",
      "Epoch : 0, Batch : 1043, Loss : 0.04496956989169121\n",
      "Epoch : 0, Batch : 1044, Loss : 0.05200894922018051\n",
      "Epoch : 0, Batch : 1045, Loss : 0.0453171581029892\n",
      "Epoch : 0, Batch : 1046, Loss : 0.042615748941898346\n",
      "Epoch : 0, Batch : 1047, Loss : 0.05498833954334259\n",
      "Epoch : 0, Batch : 1048, Loss : 0.04739280417561531\n",
      "Epoch : 0, Batch : 1049, Loss : 0.04318631440401077\n",
      "Epoch : 0, Batch : 1050, Loss : 0.045656539499759674\n",
      "Epoch : 0, Batch : 1051, Loss : 0.04863291233778\n",
      "Epoch : 0, Batch : 1052, Loss : 0.04945044964551926\n",
      "Epoch : 0, Batch : 1053, Loss : 0.04538921266794205\n",
      "Epoch : 0, Batch : 1054, Loss : 0.04999685287475586\n",
      "Epoch : 0, Batch : 1055, Loss : 0.05665150284767151\n",
      "Epoch : 0, Batch : 1056, Loss : 0.04984438791871071\n",
      "Epoch : 0, Batch : 1057, Loss : 0.056594118475914\n",
      "Epoch : 0, Batch : 1058, Loss : 0.05269563943147659\n",
      "Epoch : 0, Batch : 1059, Loss : 0.0543728768825531\n",
      "Epoch : 0, Batch : 1060, Loss : 0.05306031554937363\n",
      "Epoch : 0, Batch : 1061, Loss : 0.05011237412691116\n",
      "Epoch : 0, Batch : 1062, Loss : 0.05761714652180672\n",
      "Epoch : 0, Batch : 1063, Loss : 0.051232241094112396\n",
      "Epoch : 0, Batch : 1064, Loss : 0.051067374646663666\n",
      "Epoch : 0, Batch : 1065, Loss : 0.058878570795059204\n",
      "Epoch : 0, Batch : 1066, Loss : 0.04454073682427406\n",
      "Epoch : 0, Batch : 1067, Loss : 0.05125430226325989\n",
      "Epoch : 0, Batch : 1068, Loss : 0.05629977956414223\n",
      "Epoch : 0, Batch : 1069, Loss : 0.04892828315496445\n",
      "Epoch : 0, Batch : 1070, Loss : 0.05624459683895111\n",
      "Epoch : 0, Batch : 1071, Loss : 0.05643533542752266\n",
      "Epoch : 0, Batch : 1072, Loss : 0.045642171055078506\n",
      "Epoch : 0, Batch : 1073, Loss : 0.05197392404079437\n",
      "Epoch : 0, Batch : 1074, Loss : 0.052472565323114395\n",
      "Epoch : 0, Batch : 1075, Loss : 0.04590321704745293\n",
      "Epoch : 0, Batch : 1076, Loss : 0.04980364441871643\n",
      "Epoch : 0, Batch : 1077, Loss : 0.05607137084007263\n",
      "Epoch : 0, Batch : 1078, Loss : 0.05119132995605469\n",
      "Epoch : 0, Batch : 1079, Loss : 0.05007907748222351\n",
      "Epoch : 0, Batch : 1080, Loss : 0.05076591297984123\n",
      "Epoch : 0, Batch : 1081, Loss : 0.0485040508210659\n",
      "Epoch : 0, Batch : 1082, Loss : 0.05802132189273834\n",
      "Epoch : 0, Batch : 1083, Loss : 0.05121540650725365\n",
      "Epoch : 0, Batch : 1084, Loss : 0.047866303473711014\n",
      "Epoch : 0, Batch : 1085, Loss : 0.050503525882959366\n",
      "Epoch : 0, Batch : 1086, Loss : 0.043863892555236816\n",
      "Epoch : 0, Batch : 1087, Loss : 0.048065491020679474\n",
      "Epoch : 0, Batch : 1088, Loss : 0.05257098749279976\n",
      "Epoch : 0, Batch : 1089, Loss : 0.04834013804793358\n",
      "Epoch : 0, Batch : 1090, Loss : 0.050722282379865646\n",
      "Epoch : 0, Batch : 1091, Loss : 0.04745303839445114\n",
      "Epoch : 0, Batch : 1092, Loss : 0.04979884997010231\n",
      "Epoch : 0, Batch : 1093, Loss : 0.04844304174184799\n",
      "Epoch : 0, Batch : 1094, Loss : 0.04973119869828224\n",
      "Epoch : 0, Batch : 1095, Loss : 0.048289984464645386\n",
      "Epoch : 0, Batch : 1096, Loss : 0.0448547825217247\n",
      "Epoch : 0, Batch : 1097, Loss : 0.052933670580387115\n",
      "Epoch : 0, Batch : 1098, Loss : 0.04645286872982979\n",
      "Epoch : 0, Batch : 1099, Loss : 0.054906509816646576\n",
      "Epoch : 0, Batch : 1100, Loss : 0.0438896119594574\n",
      "Epoch : 0, Batch : 1101, Loss : 0.048174917697906494\n",
      "Epoch : 0, Batch : 1102, Loss : 0.048715248703956604\n",
      "Epoch : 0, Batch : 1103, Loss : 0.058486513793468475\n",
      "Epoch : 0, Batch : 1104, Loss : 0.040192365646362305\n",
      "Epoch : 0, Batch : 1105, Loss : 0.05211015045642853\n",
      "Epoch : 0, Batch : 1106, Loss : 0.05336356163024902\n",
      "Epoch : 0, Batch : 1107, Loss : 0.046361297369003296\n",
      "Epoch : 0, Batch : 1108, Loss : 0.054593924432992935\n",
      "Epoch : 0, Batch : 1109, Loss : 0.04809712618589401\n",
      "Epoch : 0, Batch : 1110, Loss : 0.053586047142744064\n",
      "Epoch : 0, Batch : 1111, Loss : 0.057847313582897186\n",
      "Epoch : 0, Batch : 1112, Loss : 0.05202249437570572\n",
      "Epoch : 0, Batch : 1113, Loss : 0.05628609657287598\n",
      "Epoch : 0, Batch : 1114, Loss : 0.05272456258535385\n",
      "Epoch : 0, Batch : 1115, Loss : 0.051098115742206573\n",
      "Epoch : 0, Batch : 1116, Loss : 0.0547710657119751\n",
      "Epoch : 0, Batch : 1117, Loss : 0.042681045830249786\n",
      "Epoch : 0, Batch : 1118, Loss : 0.047867245972156525\n",
      "Epoch : 0, Batch : 1119, Loss : 0.053141720592975616\n",
      "Epoch : 0, Batch : 1120, Loss : 0.05786026269197464\n",
      "Epoch : 0, Batch : 1121, Loss : 0.048154398798942566\n",
      "Epoch : 0, Batch : 1122, Loss : 0.0522325336933136\n",
      "Epoch : 0, Batch : 1123, Loss : 0.05375007539987564\n",
      "Epoch : 0, Batch : 1124, Loss : 0.04178277403116226\n",
      "Epoch : 0, Batch : 1125, Loss : 0.04783573001623154\n",
      "Epoch : 0, Batch : 1126, Loss : 0.04750065878033638\n",
      "Epoch : 0, Batch : 1127, Loss : 0.05297341197729111\n",
      "Epoch : 0, Batch : 1128, Loss : 0.04678671061992645\n",
      "Epoch : 0, Batch : 1129, Loss : 0.0571906715631485\n",
      "Epoch : 0, Batch : 1130, Loss : 0.04365197569131851\n",
      "Epoch : 0, Batch : 1131, Loss : 0.046757109463214874\n",
      "Epoch : 0, Batch : 1132, Loss : 0.04722239077091217\n",
      "Epoch : 0, Batch : 1133, Loss : 0.05266742408275604\n",
      "Epoch : 0, Batch : 1134, Loss : 0.05085419863462448\n",
      "Epoch : 0, Batch : 1135, Loss : 0.05399680882692337\n",
      "Epoch : 0, Batch : 1136, Loss : 0.05031132698059082\n",
      "Epoch : 0, Batch : 1137, Loss : 0.05690128356218338\n",
      "Epoch : 0, Batch : 1138, Loss : 0.0433068573474884\n",
      "Epoch : 0, Batch : 1139, Loss : 0.04633563011884689\n",
      "Epoch : 0, Batch : 1140, Loss : 0.051511701196432114\n",
      "Epoch : 0, Batch : 1141, Loss : 0.05475512519478798\n",
      "Epoch : 0, Batch : 1142, Loss : 0.05333131551742554\n",
      "Epoch : 0, Batch : 1143, Loss : 0.04989972710609436\n",
      "Epoch : 0, Batch : 1144, Loss : 0.048732250928878784\n",
      "Epoch : 0, Batch : 1145, Loss : 0.05178794264793396\n",
      "Epoch : 0, Batch : 1146, Loss : 0.055048637092113495\n",
      "Epoch : 0, Batch : 1147, Loss : 0.055082596838474274\n",
      "Epoch : 0, Batch : 1148, Loss : 0.05104245990514755\n",
      "Epoch : 0, Batch : 1149, Loss : 0.048409610986709595\n",
      "Epoch : 0, Batch : 1150, Loss : 0.04931439459323883\n",
      "Epoch : 0, Batch : 1151, Loss : 0.05227496847510338\n",
      "Epoch : 0, Batch : 1152, Loss : 0.04769624024629593\n",
      "Epoch : 0, Batch : 1153, Loss : 0.04965908080339432\n",
      "Epoch : 0, Batch : 1154, Loss : 0.04928220808506012\n",
      "Epoch : 0, Batch : 1155, Loss : 0.04126187041401863\n",
      "Epoch : 0, Batch : 1156, Loss : 0.04884890466928482\n",
      "Epoch : 0, Batch : 1157, Loss : 0.048439085483551025\n",
      "Epoch : 0, Batch : 1158, Loss : 0.04733080416917801\n",
      "Epoch : 0, Batch : 1159, Loss : 0.048624828457832336\n",
      "Epoch : 0, Batch : 1160, Loss : 0.04909447208046913\n",
      "Epoch : 0, Batch : 1161, Loss : 0.04925990104675293\n",
      "Epoch : 0, Batch : 1162, Loss : 0.04958309978246689\n",
      "Epoch : 0, Batch : 1163, Loss : 0.05177418515086174\n",
      "Epoch : 0, Batch : 1164, Loss : 0.049543410539627075\n",
      "Epoch : 0, Batch : 1165, Loss : 0.04540470615029335\n",
      "Epoch : 0, Batch : 1166, Loss : 0.054735392332077026\n",
      "Epoch : 0, Batch : 1167, Loss : 0.04244765266776085\n",
      "Epoch : 0, Batch : 1168, Loss : 0.05035894364118576\n",
      "Epoch : 0, Batch : 1169, Loss : 0.05521668121218681\n",
      "Epoch : 0, Batch : 1170, Loss : 0.04899859428405762\n",
      "Epoch : 0, Batch : 1171, Loss : 0.0557161346077919\n",
      "Epoch : 0, Batch : 1172, Loss : 0.054508939385414124\n",
      "Epoch : 0, Batch : 1173, Loss : 0.051064591854810715\n",
      "Epoch : 0, Batch : 1174, Loss : 0.05153466761112213\n",
      "Epoch : 0, Batch : 1175, Loss : 0.047291990369558334\n",
      "Epoch : 0, Batch : 1176, Loss : 0.049934081733226776\n",
      "Epoch : 0, Batch : 1177, Loss : 0.05071067810058594\n",
      "Epoch : 0, Batch : 1178, Loss : 0.05232053995132446\n",
      "Epoch : 0, Batch : 1179, Loss : 0.053932566195726395\n",
      "Epoch : 0, Batch : 1180, Loss : 0.049824196845293045\n",
      "Epoch : 0, Batch : 1181, Loss : 0.050122931599617004\n",
      "Epoch : 0, Batch : 1182, Loss : 0.05582805350422859\n",
      "Epoch : 0, Batch : 1183, Loss : 0.04909887909889221\n",
      "Epoch : 0, Batch : 1184, Loss : 0.04995669424533844\n",
      "Epoch : 0, Batch : 1185, Loss : 0.05152278020977974\n",
      "Epoch : 0, Batch : 1186, Loss : 0.03939447179436684\n",
      "Epoch : 0, Batch : 1187, Loss : 0.056166406720876694\n",
      "Epoch : 0, Batch : 1188, Loss : 0.04843141511082649\n",
      "Epoch : 0, Batch : 1189, Loss : 0.049584031105041504\n",
      "Epoch : 0, Batch : 1190, Loss : 0.04689021408557892\n",
      "Epoch : 0, Batch : 1191, Loss : 0.04862748086452484\n",
      "Epoch : 0, Batch : 1192, Loss : 0.055348508059978485\n",
      "Epoch : 0, Batch : 1193, Loss : 0.04854102432727814\n",
      "Epoch : 0, Batch : 1194, Loss : 0.04364527389407158\n",
      "Epoch : 0, Batch : 1195, Loss : 0.0486697256565094\n",
      "Epoch : 0, Batch : 1196, Loss : 0.05299374461174011\n",
      "Epoch : 0, Batch : 1197, Loss : 0.04062608256936073\n",
      "Epoch : 0, Batch : 1198, Loss : 0.05088600143790245\n",
      "Epoch : 0, Batch : 1199, Loss : 0.052544258534908295\n",
      "Epoch : 0, Batch : 1200, Loss : 0.04489041492342949\n",
      "Epoch : 0, Batch : 1201, Loss : 0.0548255518078804\n",
      "Epoch : 0, Batch : 1202, Loss : 0.052018940448760986\n",
      "Epoch : 0, Batch : 1203, Loss : 0.05178436264395714\n",
      "Epoch : 0, Batch : 1204, Loss : 0.051539018750190735\n",
      "Epoch : 0, Batch : 1205, Loss : 0.04808337986469269\n",
      "Epoch : 0, Batch : 1206, Loss : 0.054007578641176224\n",
      "Epoch : 0, Batch : 1207, Loss : 0.053512755781412125\n",
      "Epoch : 0, Batch : 1208, Loss : 0.052311062812805176\n",
      "Epoch : 0, Batch : 1209, Loss : 0.04972190037369728\n",
      "Epoch : 0, Batch : 1210, Loss : 0.048283807933330536\n",
      "Epoch : 0, Batch : 1211, Loss : 0.05345623940229416\n",
      "Epoch : 0, Batch : 1212, Loss : 0.04703804850578308\n",
      "Epoch : 0, Batch : 1213, Loss : 0.05386446788907051\n",
      "Epoch : 0, Batch : 1214, Loss : 0.05355016514658928\n",
      "Epoch : 0, Batch : 1215, Loss : 0.05020132660865784\n",
      "Epoch : 0, Batch : 1216, Loss : 0.049495793879032135\n",
      "Epoch : 0, Batch : 1217, Loss : 0.047247469425201416\n",
      "Epoch : 0, Batch : 1218, Loss : 0.04490949213504791\n",
      "Epoch : 0, Batch : 1219, Loss : 0.04814493656158447\n",
      "Epoch : 0, Batch : 1220, Loss : 0.055561408400535583\n",
      "Epoch : 0, Batch : 1221, Loss : 0.0451061874628067\n",
      "Epoch : 0, Batch : 1222, Loss : 0.05092163756489754\n",
      "Epoch : 0, Batch : 1223, Loss : 0.05415870249271393\n",
      "Epoch : 0, Batch : 1224, Loss : 0.05294803902506828\n",
      "Epoch : 0, Batch : 1225, Loss : 0.04894232749938965\n",
      "Epoch : 0, Batch : 1226, Loss : 0.0524657666683197\n",
      "Epoch : 0, Batch : 1227, Loss : 0.05378179997205734\n",
      "Epoch : 0, Batch : 1228, Loss : 0.05435192212462425\n",
      "Epoch : 0, Batch : 1229, Loss : 0.048233672976493835\n",
      "Epoch : 0, Batch : 1230, Loss : 0.04993849992752075\n",
      "Epoch : 0, Batch : 1231, Loss : 0.045232877135276794\n",
      "Epoch : 0, Batch : 1232, Loss : 0.044735297560691833\n",
      "Epoch : 0, Batch : 1233, Loss : 0.05245205760002136\n",
      "Epoch : 0, Batch : 1234, Loss : 0.04686012864112854\n",
      "Epoch : 0, Batch : 1235, Loss : 0.046146828681230545\n",
      "Epoch : 0, Batch : 1236, Loss : 0.047108717262744904\n",
      "Epoch : 0, Batch : 1237, Loss : 0.04752981662750244\n",
      "Epoch : 0, Batch : 1238, Loss : 0.04677466303110123\n",
      "Epoch : 0, Batch : 1239, Loss : 0.05147194117307663\n",
      "Epoch : 0, Batch : 1240, Loss : 0.04993606358766556\n",
      "Epoch : 0, Batch : 1241, Loss : 0.051298826932907104\n",
      "Epoch : 0, Batch : 1242, Loss : 0.05358538776636124\n",
      "Epoch : 0, Batch : 1243, Loss : 0.05141027644276619\n",
      "Epoch : 0, Batch : 1244, Loss : 0.051112718880176544\n",
      "Epoch : 0, Batch : 1245, Loss : 0.04713087156414986\n",
      "Epoch : 0, Batch : 1246, Loss : 0.05280463397502899\n",
      "Epoch : 0, Batch : 1247, Loss : 0.05072794109582901\n",
      "Epoch : 0, Batch : 1248, Loss : 0.05024704337120056\n",
      "Epoch : 0, Batch : 1249, Loss : 0.04408132657408714\n",
      "Epoch : 0, Batch : 1250, Loss : 0.05022764205932617\n",
      "Epoch : 0, Batch : 1251, Loss : 0.04967149347066879\n",
      "Epoch : 0, Batch : 1252, Loss : 0.04464830458164215\n",
      "Epoch : 0, Batch : 1253, Loss : 0.050842124968767166\n",
      "Epoch : 0, Batch : 1254, Loss : 0.055441223084926605\n",
      "Epoch : 0, Batch : 1255, Loss : 0.0568203330039978\n",
      "Epoch : 0, Batch : 1256, Loss : 0.04237746447324753\n",
      "Epoch : 0, Batch : 1257, Loss : 0.050883397459983826\n",
      "Epoch : 0, Batch : 1258, Loss : 0.043543264269828796\n",
      "Epoch : 0, Batch : 1259, Loss : 0.04444258660078049\n",
      "Epoch : 0, Batch : 1260, Loss : 0.043529778718948364\n",
      "Epoch : 0, Batch : 1261, Loss : 0.04296008124947548\n",
      "Epoch : 0, Batch : 1262, Loss : 0.054320819675922394\n",
      "Epoch : 0, Batch : 1263, Loss : 0.04133743792772293\n",
      "Epoch : 0, Batch : 1264, Loss : 0.05337892472743988\n",
      "Epoch : 0, Batch : 1265, Loss : 0.047972820699214935\n",
      "Epoch : 0, Batch : 1266, Loss : 0.05616682767868042\n",
      "Epoch : 0, Batch : 1267, Loss : 0.049800388514995575\n",
      "Epoch : 0, Batch : 1268, Loss : 0.049883414059877396\n",
      "Epoch : 0, Batch : 1269, Loss : 0.045825015753507614\n",
      "Epoch : 0, Batch : 1270, Loss : 0.0571688711643219\n",
      "Epoch : 0, Batch : 1271, Loss : 0.04877904802560806\n",
      "Epoch : 0, Batch : 1272, Loss : 0.05161884427070618\n",
      "Epoch : 0, Batch : 1273, Loss : 0.05659771338105202\n",
      "Epoch : 0, Batch : 1274, Loss : 0.05063813552260399\n",
      "Epoch : 0, Batch : 1275, Loss : 0.05085454508662224\n",
      "Epoch : 0, Batch : 1276, Loss : 0.049040138721466064\n",
      "Epoch : 0, Batch : 1277, Loss : 0.05163728818297386\n",
      "Epoch : 0, Batch : 1278, Loss : 0.04860440641641617\n",
      "Epoch : 0, Batch : 1279, Loss : 0.05113832280039787\n",
      "Epoch : 0, Batch : 1280, Loss : 0.05568382143974304\n",
      "Epoch : 0, Batch : 1281, Loss : 0.04835020750761032\n",
      "Epoch : 0, Batch : 1282, Loss : 0.05164818465709686\n",
      "Epoch : 0, Batch : 1283, Loss : 0.05395787954330444\n",
      "Epoch : 0, Batch : 1284, Loss : 0.0470455065369606\n",
      "Epoch : 0, Batch : 1285, Loss : 0.05088058486580849\n",
      "Epoch : 0, Batch : 1286, Loss : 0.052722781896591187\n",
      "Epoch : 0, Batch : 1287, Loss : 0.05182476341724396\n",
      "Epoch : 0, Batch : 1288, Loss : 0.04531480371952057\n",
      "Epoch : 0, Batch : 1289, Loss : 0.06113746762275696\n",
      "Epoch : 0, Batch : 1290, Loss : 0.04663975536823273\n",
      "Epoch : 0, Batch : 1291, Loss : 0.053558364510536194\n",
      "Epoch : 0, Batch : 1292, Loss : 0.05212792754173279\n",
      "Epoch : 0, Batch : 1293, Loss : 0.04694737493991852\n",
      "Epoch : 0, Batch : 1294, Loss : 0.042382366955280304\n",
      "Epoch : 0, Batch : 1295, Loss : 0.050196558237075806\n",
      "Epoch : 0, Batch : 1296, Loss : 0.04717102646827698\n",
      "Epoch : 0, Batch : 1297, Loss : 0.048269402235746384\n",
      "Epoch : 0, Batch : 1298, Loss : 0.04776735603809357\n",
      "Epoch : 0, Batch : 1299, Loss : 0.051541365683078766\n",
      "Epoch : 0, Batch : 1300, Loss : 0.05654588341712952\n",
      "Epoch : 0, Batch : 1301, Loss : 0.048809438943862915\n",
      "Epoch : 0, Batch : 1302, Loss : 0.061096761375665665\n",
      "Epoch : 0, Batch : 1303, Loss : 0.04775155335664749\n",
      "Epoch : 0, Batch : 1304, Loss : 0.051610976457595825\n",
      "Epoch : 0, Batch : 1305, Loss : 0.04630567133426666\n",
      "Epoch : 0, Batch : 1306, Loss : 0.04836153984069824\n",
      "Epoch : 0, Batch : 1307, Loss : 0.05693842098116875\n",
      "Epoch : 0, Batch : 1308, Loss : 0.039704881608486176\n",
      "Epoch : 0, Batch : 1309, Loss : 0.046865545213222504\n",
      "Epoch : 0, Batch : 1310, Loss : 0.045694053173065186\n",
      "Epoch : 0, Batch : 1311, Loss : 0.04668061435222626\n",
      "Epoch : 0, Batch : 1312, Loss : 0.045239776372909546\n",
      "Epoch : 0, Batch : 1313, Loss : 0.045142218470573425\n",
      "Epoch : 0, Batch : 1314, Loss : 0.05182715505361557\n",
      "Epoch : 0, Batch : 1315, Loss : 0.05181659013032913\n",
      "Epoch : 0, Batch : 1316, Loss : 0.05035773292183876\n",
      "Epoch : 0, Batch : 1317, Loss : 0.05072280392050743\n",
      "Epoch : 0, Batch : 1318, Loss : 0.05164778605103493\n",
      "Epoch : 0, Batch : 1319, Loss : 0.05284944549202919\n",
      "Epoch : 0, Batch : 1320, Loss : 0.05499008297920227\n",
      "Epoch : 0, Batch : 1321, Loss : 0.04787503182888031\n",
      "Epoch : 0, Batch : 1322, Loss : 0.04565676301717758\n",
      "Epoch : 0, Batch : 1323, Loss : 0.05169467255473137\n",
      "Epoch : 0, Batch : 1324, Loss : 0.048187121748924255\n",
      "Epoch : 0, Batch : 1325, Loss : 0.051440078765153885\n",
      "Epoch : 0, Batch : 1326, Loss : 0.04530807584524155\n",
      "Epoch : 0, Batch : 1327, Loss : 0.05208616331219673\n",
      "Epoch : 0, Batch : 1328, Loss : 0.04638427495956421\n",
      "Epoch : 0, Batch : 1329, Loss : 0.04648938775062561\n",
      "Epoch : 0, Batch : 1330, Loss : 0.049466054886579514\n",
      "Epoch : 0, Batch : 1331, Loss : 0.04792829602956772\n",
      "Epoch : 0, Batch : 1332, Loss : 0.04828786849975586\n",
      "Epoch : 0, Batch : 1333, Loss : 0.05340760573744774\n",
      "Epoch : 0, Batch : 1334, Loss : 0.04629651457071304\n",
      "Epoch : 0, Batch : 1335, Loss : 0.04364059120416641\n",
      "Epoch : 0, Batch : 1336, Loss : 0.048735231161117554\n",
      "Epoch : 0, Batch : 1337, Loss : 0.051673561334609985\n",
      "Epoch : 0, Batch : 1338, Loss : 0.05270499736070633\n",
      "Epoch : 0, Batch : 1339, Loss : 0.056173596531152725\n",
      "Epoch : 0, Batch : 1340, Loss : 0.0507645383477211\n",
      "Epoch : 0, Batch : 1341, Loss : 0.05138404667377472\n",
      "Epoch : 0, Batch : 1342, Loss : 0.04905534163117409\n",
      "Epoch : 0, Batch : 1343, Loss : 0.05936651676893234\n",
      "Epoch : 0, Batch : 1344, Loss : 0.05655360966920853\n",
      "Epoch : 0, Batch : 1345, Loss : 0.04365406930446625\n",
      "Epoch : 0, Batch : 1346, Loss : 0.04517315328121185\n",
      "Epoch : 0, Batch : 1347, Loss : 0.0445975586771965\n",
      "Epoch : 0, Batch : 1348, Loss : 0.04797542095184326\n",
      "Epoch : 0, Batch : 1349, Loss : 0.052694886922836304\n",
      "Epoch : 0, Batch : 1350, Loss : 0.04484516382217407\n",
      "Epoch : 0, Batch : 1351, Loss : 0.050837621092796326\n",
      "Epoch : 0, Batch : 1352, Loss : 0.04805237799882889\n",
      "Epoch : 0, Batch : 1353, Loss : 0.05141414701938629\n",
      "Epoch : 0, Batch : 1354, Loss : 0.05248530954122543\n",
      "Epoch : 0, Batch : 1355, Loss : 0.05250917375087738\n",
      "Epoch : 0, Batch : 1356, Loss : 0.053160786628723145\n",
      "Epoch : 0, Batch : 1357, Loss : 0.04452763870358467\n",
      "Epoch : 0, Batch : 1358, Loss : 0.048195984214544296\n",
      "Epoch : 0, Batch : 1359, Loss : 0.04331663250923157\n",
      "Epoch : 0, Batch : 1360, Loss : 0.05263803154230118\n",
      "Epoch : 0, Batch : 1361, Loss : 0.041853662580251694\n",
      "Epoch : 0, Batch : 1362, Loss : 0.052033983170986176\n",
      "Epoch : 0, Batch : 1363, Loss : 0.048916831612586975\n",
      "Epoch : 0, Batch : 1364, Loss : 0.04771185666322708\n",
      "Epoch : 0, Batch : 1365, Loss : 0.048312634229660034\n",
      "Epoch : 0, Batch : 1366, Loss : 0.0528874546289444\n",
      "Epoch : 0, Batch : 1367, Loss : 0.055602557957172394\n",
      "Epoch : 0, Batch : 1368, Loss : 0.051853492856025696\n",
      "Epoch : 0, Batch : 1369, Loss : 0.052713073790073395\n",
      "Epoch : 0, Batch : 1370, Loss : 0.048663653433322906\n",
      "Epoch : 0, Batch : 1371, Loss : 0.05469562113285065\n",
      "Epoch : 0, Batch : 1372, Loss : 0.05772002786397934\n",
      "Epoch : 0, Batch : 1373, Loss : 0.05276992544531822\n",
      "Epoch : 0, Batch : 1374, Loss : 0.04824638366699219\n",
      "Epoch : 0, Batch : 1375, Loss : 0.05648336559534073\n",
      "Epoch : 0, Batch : 1376, Loss : 0.055878546088933945\n",
      "Epoch : 0, Batch : 1377, Loss : 0.047320835292339325\n",
      "Epoch : 0, Batch : 1378, Loss : 0.04341724142432213\n",
      "Epoch : 0, Batch : 1379, Loss : 0.05757967755198479\n",
      "Epoch : 0, Batch : 1380, Loss : 0.047931209206581116\n",
      "Epoch : 0, Batch : 1381, Loss : 0.046647824347019196\n",
      "Epoch : 0, Batch : 1382, Loss : 0.054430216550827026\n",
      "Epoch : 0, Batch : 1383, Loss : 0.04487196356058121\n",
      "Epoch : 0, Batch : 1384, Loss : 0.05127697065472603\n",
      "Epoch : 0, Batch : 1385, Loss : 0.05362403765320778\n",
      "Epoch : 0, Batch : 1386, Loss : 0.05157129466533661\n",
      "Epoch : 0, Batch : 1387, Loss : 0.054152071475982666\n",
      "Epoch : 0, Batch : 1388, Loss : 0.05259634926915169\n",
      "Epoch : 0, Batch : 1389, Loss : 0.05371985584497452\n",
      "Epoch : 0, Batch : 1390, Loss : 0.05175826698541641\n",
      "Epoch : 0, Batch : 1391, Loss : 0.056334488093853\n",
      "Epoch : 0, Batch : 1392, Loss : 0.05443190410733223\n",
      "Epoch : 0, Batch : 1393, Loss : 0.052761808037757874\n",
      "Epoch : 0, Batch : 1394, Loss : 0.04596651718020439\n",
      "Epoch : 0, Batch : 1395, Loss : 0.047234632074832916\n",
      "Epoch : 0, Batch : 1396, Loss : 0.050699539482593536\n",
      "Epoch : 0, Batch : 1397, Loss : 0.05515588819980621\n",
      "Epoch : 0, Batch : 1398, Loss : 0.059914156794548035\n",
      "Epoch : 0, Batch : 1399, Loss : 0.05930572748184204\n",
      "Epoch : 0, Batch : 1400, Loss : 0.04465591907501221\n",
      "Epoch : 0, Batch : 1401, Loss : 0.05013120919466019\n",
      "Epoch : 0, Batch : 1402, Loss : 0.04863838851451874\n",
      "Epoch : 0, Batch : 1403, Loss : 0.04736042767763138\n",
      "Epoch : 0, Batch : 1404, Loss : 0.05004917085170746\n",
      "Epoch : 0, Batch : 1405, Loss : 0.05150420591235161\n",
      "Epoch : 0, Batch : 1406, Loss : 0.05288633704185486\n",
      "Epoch : 0, Batch : 1407, Loss : 0.04736419394612312\n",
      "Epoch : 0, Batch : 1408, Loss : 0.05116569995880127\n",
      "Epoch : 0, Batch : 1409, Loss : 0.04270372912287712\n",
      "Epoch : 0, Batch : 1410, Loss : 0.05388404801487923\n",
      "Epoch : 0, Batch : 1411, Loss : 0.0471658818423748\n",
      "Epoch : 0, Batch : 1412, Loss : 0.050561659038066864\n",
      "Epoch : 0, Batch : 1413, Loss : 0.0445132851600647\n",
      "Epoch : 0, Batch : 1414, Loss : 0.04615601897239685\n",
      "Epoch : 0, Batch : 1415, Loss : 0.04609990864992142\n",
      "Epoch : 0, Batch : 1416, Loss : 0.05615459382534027\n",
      "Epoch : 0, Batch : 1417, Loss : 0.045582257211208344\n",
      "Epoch : 0, Batch : 1418, Loss : 0.051479022949934006\n",
      "Epoch : 0, Batch : 1419, Loss : 0.05499798059463501\n",
      "Epoch : 0, Batch : 1420, Loss : 0.048139650374650955\n",
      "Epoch : 0, Batch : 1421, Loss : 0.04992130771279335\n",
      "Epoch : 0, Batch : 1422, Loss : 0.0522250272333622\n",
      "Epoch : 0, Batch : 1423, Loss : 0.05062541738152504\n",
      "Epoch : 0, Batch : 1424, Loss : 0.05279063433408737\n",
      "Epoch : 0, Batch : 1425, Loss : 0.052187081426382065\n",
      "Epoch : 0, Batch : 1426, Loss : 0.0508224219083786\n",
      "Epoch : 0, Batch : 1427, Loss : 0.05591723322868347\n",
      "Epoch : 0, Batch : 1428, Loss : 0.058372076600790024\n",
      "Epoch : 0, Batch : 1429, Loss : 0.046581052243709564\n",
      "Epoch : 0, Batch : 1430, Loss : 0.05675790458917618\n",
      "Epoch : 0, Batch : 1431, Loss : 0.04872036725282669\n",
      "Epoch : 0, Batch : 1432, Loss : 0.046667665243148804\n",
      "Epoch : 0, Batch : 1433, Loss : 0.050017036497592926\n",
      "Epoch : 0, Batch : 1434, Loss : 0.051421813666820526\n",
      "Epoch : 0, Batch : 1435, Loss : 0.05340787023305893\n",
      "Epoch : 0, Batch : 1436, Loss : 0.05955507978796959\n",
      "Epoch : 0, Batch : 1437, Loss : 0.045334480702877045\n",
      "Epoch : 0, Batch : 1438, Loss : 0.047144703567028046\n",
      "Epoch : 0, Batch : 1439, Loss : 0.049794621765613556\n",
      "Epoch : 0, Batch : 1440, Loss : 0.05526087433099747\n",
      "Epoch : 0, Batch : 1441, Loss : 0.046853289008140564\n",
      "Epoch : 0, Batch : 1442, Loss : 0.047989483922719955\n",
      "Epoch : 0, Batch : 1443, Loss : 0.054619841277599335\n",
      "Epoch : 0, Batch : 1444, Loss : 0.046744562685489655\n",
      "Epoch : 0, Batch : 1445, Loss : 0.05265141278505325\n",
      "Epoch : 0, Batch : 1446, Loss : 0.04668556898832321\n",
      "Epoch : 0, Batch : 1447, Loss : 0.04784312844276428\n",
      "Epoch : 0, Batch : 1448, Loss : 0.0441519059240818\n",
      "Epoch : 0, Batch : 1449, Loss : 0.05275798588991165\n",
      "Epoch : 0, Batch : 1450, Loss : 0.03947388380765915\n",
      "Epoch : 0, Batch : 1451, Loss : 0.047311559319496155\n",
      "Epoch : 0, Batch : 1452, Loss : 0.05165889114141464\n",
      "Epoch : 0, Batch : 1453, Loss : 0.05129270255565643\n",
      "Epoch : 0, Batch : 1454, Loss : 0.05284733325242996\n",
      "Epoch : 0, Batch : 1455, Loss : 0.06031261384487152\n",
      "Epoch : 0, Batch : 1456, Loss : 0.04983443394303322\n",
      "Epoch : 0, Batch : 1457, Loss : 0.04700182378292084\n",
      "Epoch : 0, Batch : 1458, Loss : 0.05017765611410141\n",
      "Epoch : 0, Batch : 1459, Loss : 0.04701915383338928\n",
      "Epoch : 0, Batch : 1460, Loss : 0.052958015352487564\n",
      "Epoch : 0, Batch : 1461, Loss : 0.04322992265224457\n",
      "Epoch : 0, Batch : 1462, Loss : 0.055068355053663254\n",
      "Epoch : 0, Batch : 1463, Loss : 0.050645772367715836\n",
      "Epoch : 0, Batch : 1464, Loss : 0.051240451633930206\n",
      "Epoch : 0, Batch : 1465, Loss : 0.04473473131656647\n",
      "Epoch : 0, Batch : 1466, Loss : 0.05414596199989319\n",
      "Epoch : 0, Batch : 1467, Loss : 0.04516462981700897\n",
      "Epoch : 0, Batch : 1468, Loss : 0.04934854060411453\n",
      "Epoch : 0, Batch : 1469, Loss : 0.051601383835077286\n",
      "Epoch : 0, Batch : 1470, Loss : 0.04663122445344925\n",
      "Epoch : 0, Batch : 1471, Loss : 0.05252174288034439\n",
      "Epoch : 0, Batch : 1472, Loss : 0.04662087559700012\n",
      "Epoch : 0, Batch : 1473, Loss : 0.05619287118315697\n",
      "Epoch : 0, Batch : 1474, Loss : 0.05482643097639084\n",
      "Epoch : 0, Batch : 1475, Loss : 0.047523707151412964\n",
      "Epoch : 0, Batch : 1476, Loss : 0.04852985590696335\n",
      "Epoch : 0, Batch : 1477, Loss : 0.06488577276468277\n"
     ]
    }
   ],
   "source": [
    "t.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
